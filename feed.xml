<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Western Devs</title>
  
  <link href="/feed.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.westerndevs.com" rel="alternate" type="application/atom+xml"/>
  
  <updated>2017-08-17T15:01:57.513Z</updated>
  <id>http://www.westerndevs.com/</id>
  
  <author>
    <name>Western Devs</name>
	<uri>http://www.westerndevs.com</uri>
    <email>info@westerndevs.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title type="html">Posh-GVM, the Groovy Version Manager for Powershell</title>
    <link href="http://www.westerndevs.com/java/posh-gvm/" rel="alternate" type="text/html"/>
    <id>http://www.westerndevs.com/java/posh-gvm/</id>
    <published>2017-08-17T14:00:00.000Z</published>
    <updated>2017-08-17T15:01:57.513Z</updated>
	<author>
	
	  
	  <name>David Wesst</name>
	  <email>questions@davidwesst.com</email>
	
	  <uri>http://www.westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Here's another dev thing I use: <a href="https://github.com/flofreud/posh-gvm" target="_blank" rel="external">Posh-GVM</a>, a Groovy version manager that works for Windows.</p><p>You remember Groovy right? The language that was all the rage at some point with Groovy on Grails?</p><p>All kidding aside, in my adventures as an enterprise JDK developer, I've come across a number of Groovy on Grails applications. These projects tend to span multiple versions of Grails, ranging from 2.3.x which works on older versions of Tomcat, upto 3.2.x for of of our newer solutions. Instead of manually configuring my system for each project, I just use Posh-GVM as recommended by the folks who brought you <a href="http://sdkman.io/" target="_blank" rel="external">SDKMan for Unix systems</a>.</p><p><img src="https://davidwesst.blob.core.windows.net/blog/posh-gvm/poshgvm-example.gif" alt="Posh-GVM in action" title="Posh-GVM in action in a Powershell terminal"></p><h2>What does it do?</h2><p>It handles switching between versions of Groovy, Grails, and a bunch more technologies without having to fuss with configuring your system. It switch between versions of Grails, Groovy, Gradle, Koitlin, and more with <code>gvm use &lt;candidate&gt; &lt;version&gt;</code> where candidate is the technology and version is...well, the version.</p><h2>Using Posh-GVM</h2><p>Posh-GVM is a Windows port to <a href="http://sdkman.io/" target="_blank" rel="external">SDKMan</a> formerly known as the GVM, or Groovy eVironment Manager. Instead of requiring a Unix system to run, it requires Powershell.</p><p>To install it, I followed the README instructions to install it via <a href="https://github.com/flofreud/posh-gvm#via-short-script" target="_blank" rel="external">a short script</a>. I tried using the PsGet method described, but didn't have any luck finding the module. More on that later.</p><p>Once installed (and added to your profile) you can run <code>gvm help</code> in the Powershell terminal and you should see a lovely help menu with all the goodies you can install and switch your fingertips.</p><h3>Won't these conflict with the versions I already have installed?</h3><p>No. It installs the tools in a different directory, so you should be good.</p><p>That being said, you probably don't need to have a local version of Grails or whatever tool installed anymore because Posh-GVM will handle that for you.</p><h2>What makes it cool?</h2><p>It's cool because it works on Windows, without the need for Bash or Cygwin.</p><p>The fact that it covers a number of tools, including Grails, Groovy, and Gradle (and many more) is a pretty nifty too.</p><h2>What are the drawbacks?</h2><p>There are two that stand out to me, but nothing that has made me abandon the tool for something else.</p><h3>Java not included</h3><p>The first being that it doesn't support Java like it's Unix couterpart. My guess is that Java is something special when it comes to Unix VS Windows and was eliminated for that reason. We have <a href="http://www.westerndevs.com/java/jabba/" title="My post on Jabba, the Java version manager for everyone">Jabba</a> for that on Windows, but it would be nice to have all the pieces in to the puzzle in a single tool.</p><h3>Lack of Project Activity</h3><p>The second is the lack of updates.</p><p>As of this writing, it hasn't been updated since <a href="https://github.com/flofreud/posh-gvm/commit/2145f8a65c5bf317e96664ebb03bf84c569ba770" target="_blank" rel="external">December 2015</a> while SDKMan has continued to be actively developed.</p><p>This isn't necessarily a bad thing, as there haven't been any pull requests in quite some time either. It's just something I note as a risk when I adopt an open source tool.</p><hr><p>Ultimately, I think this tool is a great solution for people that need to use any of these tools, but don't want to couple themselves to Cygwin or Bash for Windows. It has solved my Grails, Groovy, and Gradle versioning issues on Windows, and that is more than enough to make it a win in my books.</p>]]></content>
    
    <summary type="html">
    
      Here&#39;s another dev thing I use: Posh-GVM, a Groovy version manager that works for Windows.
    
    </summary>
    
      <category term="java" scheme="http://www.westerndevs.com/categories/java/"/>
    
    
      <category term="powershell" scheme="http://www.westerndevs.com/tags/powershell/"/>
    
      <category term="version manager" scheme="http://www.westerndevs.com/tags/version-manager/"/>
    
      <category term="grails" scheme="http://www.westerndevs.com/tags/grails/"/>
    
      <category term="groovy" scheme="http://www.westerndevs.com/tags/groovy/"/>
    
      <category term="gradle" scheme="http://www.westerndevs.com/tags/gradle/"/>
    
  </entry>
  
  <entry>
    <title type="html">Jabba, the Java Version Manager for Everyone</title>
    <link href="http://www.westerndevs.com/java/jabba/" rel="alternate" type="text/html"/>
    <id>http://www.westerndevs.com/java/jabba/</id>
    <published>2017-08-16T13:35:00.000Z</published>
    <updated>2017-08-17T15:01:57.513Z</updated>
	<author>
	
	  
	  <name>David Wesst</name>
	  <email>questions@davidwesst.com</email>
	
	  <uri>http://www.westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Here's another dev thing I use: <a href="https://github.com/shyiko/jabba" target="_blank" rel="external">Jabba</a>, a cross-platform Java version manager that works for Windows.</p><p>Over the the past few years, I've been doing JDK-based development in an enterprise Windows environment. In that time, I've continually struggled with being able to easily switch between versions of Java on my machine, depending on the project. We have legacy application that run old Java, and modern applications that run newer versions of Java. Being able to switch versions, without having to manually change my environment variables or handle mula</p><p>Now, that is no longer a problem thanks to my good friend, Jabba.</p><p><img src="https://davidwesst.blob.core.windows.net/blog/jabba/jabba-example.gif" alt="Jabba in Action" title="Jabba in Action in a Powershell terminal"></p><h2>What does it do?</h2><p>Exactly what you think: it changes the version of Java you're running on the fly. No need to install anything or worry about conflicting versions, or searching out and installing the specific Java version you need for your project.</p><h2>Using Jabba</h2><p>First thing is installing Jabba, which is a breeze thanks to the following the <a href="https://github.com/shyiko/jabba#windows-10" target="_blank" rel="external">instructions provided</a> in the repository README. After that, I included it in my Powershell profile so it initializes it when I start Powershell.</p><figure class="highlight taggerscript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"># Jabba</div><div class="line">if (Test-Path "H:<span class="symbol">\U</span>sers<span class="symbol">\d</span>w<span class="symbol">\.</span>jabba<span class="symbol">\j</span>abba.ps1") </div><div class="line">&#123; </div><div class="line">   . "$&#123;HOME&#125;<span class="symbol">\.</span>jabba<span class="symbol">\j</span>abba.ps1" </div><div class="line">&#125;</div></pre></td></tr></table></figure><p>To test it out, I run a <code>refreshenv</code> command in the Powershell window, and run <code>jabba -h</code> to see if I get the help file.The commands are pretty straightforward. You can list all the available versions, using <code>jabba ls-remote</code>, install the one(s) you need need with <code>jabba install my-version</code> and you're good to go to run that version of Java.</p><figure class="highlight stata"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">H</span>:\src</div><div class="line">&gt; jabba</div><div class="line">Java <span class="keyword">Version</span> Manager (https:<span class="comment">//github.com/shyiko/jabba).</span></div><div class="line"></div><div class="line">Usage:</div><div class="line">  jabba [flags]</div><div class="line">  jabba [command]</div><div class="line"></div><div class="line">Available Commands:</div><div class="line">  install     Download and install JDK</div><div class="line">  uninstall   Uninstall JDK</div><div class="line">  link        Resolve or <span class="keyword">update</span> a link</div><div class="line">  unlink      Delete a link</div><div class="line">  <span class="keyword">use</span>         Modify PATH &amp; JAVA_HOME to <span class="keyword">use</span> specific JDK</div><div class="line">  current     <span class="keyword">Display</span> currently '<span class="keyword">use</span>'<span class="keyword">ed</span> <span class="keyword">version</span></div><div class="line">  <span class="keyword">ls</span>          <span class="keyword">List</span> installed versions</div><div class="line">  <span class="keyword">ls</span>-remote   <span class="keyword">List</span> remote versions available <span class="keyword">for</span> install</div><div class="line">  deactivate  Undo effects of `jabba` <span class="keyword">on</span> current <span class="keyword">shell</span></div><div class="line">  alias       Resolve or <span class="keyword">update</span> <span class="keyword">an</span> alias</div><div class="line">  unalias     Delete <span class="keyword">an</span> alias</div><div class="line">  <span class="keyword">which</span>       <span class="keyword">Display</span> path to installed JDK</div><div class="line"></div><div class="line">Flags:</div><div class="line">      --<span class="keyword">version</span>   <span class="keyword">version</span> of jabba</div><div class="line"></div><div class="line"><span class="keyword">Use</span> <span class="string">"jabba [command] --help"</span> <span class="keyword">for</span> <span class="keyword">more</span> information <span class="keyword">about</span> a command.</div></pre></td></tr></table></figure><p>And now you're good to go with whatever version of Java your current command line needs.</p><h3>Won't this conflict with my installed version of Java?</h3><p>Nope. The <a href="https://github.com/shyiko/jabba#faq" target="_blank" rel="external">FAQ</a> section of the README covers that.</p><p>In my case, I uninstalled all the different JDK's I had installed to ensure there were no conflicts, and I like to remove tools I'm no longer needing on my machine.</p><h3>But what about my really old legacy JDK on my machine?</h3><p>If you check the <a href="https://github.com/shyiko/jabba#usage" target="_blank" rel="external">usage</a> section of the README, you can use Jabba to install JDKs that are hosted in a custom spot.</p><p>In the case of the depracated versions of Java that are difficult to come by, I use the Zulu or OpenJDK versions that are available through Jabba. You can see them when you run <code>jabba ls-remote</code>. It's not an exact replica of the Oracle JDK, but I haven't hit any issues in my legacy enterprise applications.</p><h2>What makes it cool?</h2><p>My prefernce for any dev tool is to have it available through the command line.</p><p>When it comes to Java and Windows, the command line tools out there for Java are a bit limited. The standard answer seems to be to use Powershell to update your environment variables, but that doesn't solve the need to find and install the version I need.</p><p>Jabba solves that for me.</p><p>Plus, since it's written in Go, it works on OSX and Linux, so anyone can use the tool.</p><p>And just to put some more icing on the cake, the solo developer building Jabba was kind enough to implement <a href="https://github.com/shyiko/jabba/issues/67#issuecomment-300869749" target="_blank" rel="external">a feature I supported</a> on over a weekend which made the tool work even better for me at work and at home. So, thank you <a href="https://github.com/shyiko" target="_blank" rel="external">Stanley Shyiko</a>.</p><h2>What are the drawbacks?</h2><p>I haven't hit any so far, which is pretty impressive considering I use this tools almost every day.</p><hr><p>If you're an enterprise Java developer that needs to support legacy applications, I would strongly suggest taking a look at Jabba. With <a href="https://support.microsoft.com/en-ca/help/13853/windows-lifecycle-fact-sheet" target="_blank" rel="external">Windows 7 extended support ending</a> in the next few years, your enterprise will be looking to move you to a new OS, Windows 10 or otherwise.</p><p>With Jabba, you'll at least have a tool that works regardless of how your development machine changes.</p>]]></content>
    
    <summary type="html">
    
      Here&#39;s another dev thing I use: Jabba, a cross-platform Java version manager that works for Windows.
    
    </summary>
    
      <category term="java" scheme="http://www.westerndevs.com/categories/java/"/>
    
    
      <category term="powershell" scheme="http://www.westerndevs.com/tags/powershell/"/>
    
      <category term="version manager" scheme="http://www.westerndevs.com/tags/version-manager/"/>
    
      <category term="java" scheme="http://www.westerndevs.com/tags/java/"/>
    
      <category term="jabba" scheme="http://www.westerndevs.com/tags/jabba/"/>
    
  </entry>
  
  <entry>
    <title type="html">Developer Health</title>
    <link href="http://www.westerndevs.com/podcasts/Developer-Health/" rel="alternate" type="text/html"/>
    <id>http://www.westerndevs.com/podcasts/Developer-Health/</id>
    <published>2017-08-15T21:02:36.000Z</published>
    <updated>2017-08-17T15:01:57.513Z</updated>
	<author>
		  
	  <name>Western Devs</name>
	  <email>info@westerndevs.com</email>	  
	
	  <uri>http://www.westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<h3>Synopsis</h3><ul><li>Dealing with &quot;you have to do this for the rest of your  life&quot;</li><li>Evaluating consumption</li><li>Cross-fit is <s>fun</s> a thing</li><li>Maintaining motivation</li><li>Creating measurable and appropriate goals</li><li>Combining exercise with work</li><li>Weight vs. body fat</li><li>Tweaking the metrics</li><li>Importance of having a plan</li><li>The motivation of being yelled at</li><li>Find a community</li><li>Outsourcing your health plan</li><li>Keeping it simple and creating habits</li><li>Using technology</li><li>Measuring regularly</li><li>The challenge of eating properly when you work from home</li><li>Getting your kids involved</li><li>The psychology of hunger</li><li>Activities performed by Western Devs in the making of this episode: running, cross-fit, hockey, boxing, weights, tennis, devopsing, microservicing, and competitive breathing.</li></ul>]]></content>
    
    <summary type="html">
    
      The Western Devs aren&#39;t getting any younger. We take time out of our exercise routines to talk about keeping healthy
    
    </summary>
    
      <category term="podcasts" scheme="http://www.westerndevs.com/categories/podcasts/"/>
    
    
  </entry>
  
  <entry>
    <title type="html">NVS, the Node Version Manger for Everyone</title>
    <link href="http://www.westerndevs.com/javascript/nvs/" rel="alternate" type="text/html"/>
    <id>http://www.westerndevs.com/javascript/nvs/</id>
    <published>2017-08-15T16:35:00.000Z</published>
    <updated>2017-08-17T15:01:57.513Z</updated>
	<author>
	
	  
	  <name>David Wesst</name>
	  <email>questions@davidwesst.com</email>
	
	  <uri>http://www.westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Here's another dev thing I use: <a href="https://github.com/jasongin/nvs" target="_blank" rel="external">NVS</a>, a cross-platform Node version manager that works for Windows.</p><p>It's no secret that I like JavaScript, which includes <a href="nodejs.org/">Node</a>. The history of Node releases has been fast, furious, and <a href="https://stackoverflow.com/questions/27309412/what-is-the-difference-between-node-js-and-io-js" target="_blank" rel="external">somewhat turbulent</a> which led to a lot of different versions of Node being released. Manually managing the version of Node in you development enviornment is painful, just like it is for Java. For the Linux and Unix people, there was <a href="https://github.com/creationix/nvm" target="_blank" rel="external">nvm</a> and <a href="https://github.com/tj/n" target="_blank" rel="external">n</a>, but nothing really comparable for Windows.</p><p>Until NVS that is.</p><h2>What does it do?</h2><p>The Node Version Switcher switches versions of Node in environment. So, if you need to jump from 4.8.4 to 6.11.1, no problem. Just a quick <code>nvs add 6.11.1</code> and <code>nvs use 6.11.1</code> and you're ready to go.</p><p>No downloading binaries. No changing environment variables.</p><h2>Using NVS</h2><p>Although supported on <a href="https://github.com/jasongin/nvs#mac-linux" target="_blank" rel="external">OSX and Linux</a>, I'm going to focus on Windows as that is the environment where I use it the most.</p><p>You have two different installtion options on Windows, the first being a traditional installer file that you can download from <a href="https://github.com/jasongin/nvs/releases" target="_blank" rel="external">the release page</a> for the project.</p><p>The second is using <a href="https://github.com/jasongin/nvs/blob/master/doc/SETUP.md#manual-setup---powershell" target="_blank" rel="external">Powershell</a> or the good old fashioned <a href="https://github.com/jasongin/nvs/blob/master/doc/SETUP.md#manual-setup---command-prompt" target="_blank" rel="external">command line</a>, both of which are described on the <a href="https://github.com/jasongin/nvs/blob/master/doc/SETUP.md" target="_blank" rel="external">setup page</a> for the project.</p><p>NVS even supported Bash for Windows, which is pretty great for those Linux-y Windows people, although it requires a few manual configuration steps.</p><p>Once you get things installed, you can run <code>nvs</code> and go through the interactive menu goodness to get your favourite flavour of Node installed.</p><p><img src="https://davidwesst.blob.core.windows.net/blog/nvs/nvs-menu.gif" alt="NVS Interactive Console Menu" title="NVS Consle Menu in Action"></p><p>I really dig this interactive command line menu, which was created by the NVS author for NVS, and eventually turned into it's own library called <a href="https://github.com/jasongin/console-menu" target="_blank" rel="external">console-menu</a>. But that is post for another time.</p><h3>Won't this conflict with my installed version of Node?</h3><p>Not from my experience.</p><p>When I started with NVS, I had a version of Node installed, but I ended up uninstalling just to simplify my development environment. I kept forgetting that I had a base installation of Node installed. This confusion would result in me running <code>node --version</code> only to get a conflicting version number than the one I would see in my Windows Application list, and get me triaging an issue that didn't exist.</p><p>Plus, NVS provides a feature to set a default version of using the <code>nvs link</code> command.</p><h3>What about the global packages I've installed?</h3><p>In the case where you install a package globally using a certain version of Node, when you switch to a different version, you could face some problems. More specifically, around code features available in Node based on what version of Node you've installed, or around the nested dependencies that get installed as part of a package your project needs.</p><p>Not an issue, as NVS provides the <code>migrate</code> command to move packages, global or otherwise from one version of Node to another.</p><h3>But what about my weird, custom Node versions?</h3><p>No issue, because you can point to whatever directory you want as source for Node binaries using the <a href="https://github.com/jasongin/nvs/blob/master/doc/ALIAS.md#aliasing-directories" target="_blank" rel="external">aliasing capabilities</a>.</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">C:<span class="tag">\<span class="name">Users</span></span><span class="tag">\<span class="name">dw</span></span><span class="tag">\<span class="name">src</span></span><span class="tag">\<span class="name">_</span></span>scratch</div><div class="line">&gt; node --version</div><div class="line">v8.1.4</div><div class="line"></div><div class="line">C:<span class="tag">\<span class="name">Users</span></span><span class="tag">\<span class="name">dw</span></span><span class="tag">\<span class="name">src</span></span><span class="tag">\<span class="name">_</span></span>scratch</div><div class="line">&gt; nvs use chakracore/8.1.2</div><div class="line">PATH -= <span class="formula">$env:LOCALAPPDATA<span class="tag">\<span class="name">nvs</span></span><span class="tag">\<span class="name">chakracore</span></span><span class="tag">\</span>8.1.4<span class="tag">\<span class="name">x</span></span>64</span></div><div class="line"><span class="formula">PATH += $</span>env:LOCALAPPDATA<span class="tag">\<span class="name">nvs</span></span><span class="tag">\<span class="name">chakracore</span></span><span class="tag">\</span>8.1.2<span class="tag">\<span class="name">x</span></span>64</div><div class="line"></div><div class="line">C:<span class="tag">\<span class="name">Users</span></span><span class="tag">\<span class="name">dw</span></span><span class="tag">\<span class="name">src</span></span><span class="tag">\<span class="name">_</span></span>scratch</div><div class="line">&gt; node --version</div><div class="line">v8.1.2</div></pre></td></tr></table></figure><h2>What makes it cool?</h2><p>It's cross-platform, so that's pretty awesome. But, there's more stuff that I haven't touched on in this post.</p><p>For example, there is bundled integration with <a href="https://github.com/jasongin/nvs#vs-code-support" target="_blank" rel="external">Visual Studio Code</a> which is a huge cross-platform bonus for me. VS Code is my editor of choice, and considering that it too is cross-platform, this is pretty great.</p><p>Other coolness to note would be things like <a href="https://github.com/jasongin/nvs#aliases" target="_blank" rel="external">aliasing</a> and <a href="">automatic directory swtiching</a>(https://github.com/jasongin/nvs#automatic-switching-per-directory). Not to mention that it supports <a href="https://github.com/nodejs/node-chakracore" target="_blank" rel="external">ChrakraCore</a>, making it easy to turn it on for all your <a href="https://github.com/nodejs/node-chakracore#time-travel-debugging" target="_blank" rel="external">Time Travel Debugging</a> needs.</p><p>All of that is icing on a delicious dev tool cake.</p><h2>What are the drawbacks?</h2><p>Honestly, I'm not sure. I haven't found any so far, so that counts for something.</p><hr><p>At the end of the day NVS does the job, and it does the job well. Plus, it comes with a bunch of cool extras that can make your Node development experience even more smooth.</p>]]></content>
    
    <summary type="html">
    
      Here&#39;s another dev thing I use: NVS, or the Node Version Switcher. It works on Windows and it&#39;s great.
    
    </summary>
    
      <category term="javascript" scheme="http://www.westerndevs.com/categories/javascript/"/>
    
    
      <category term="javascript" scheme="http://www.westerndevs.com/tags/javascript/"/>
    
      <category term="node" scheme="http://www.westerndevs.com/tags/node/"/>
    
      <category term="powershell" scheme="http://www.westerndevs.com/tags/powershell/"/>
    
      <category term="nvs" scheme="http://www.westerndevs.com/tags/nvs/"/>
    
      <category term="version manager" scheme="http://www.westerndevs.com/tags/version-manager/"/>
    
  </entry>
  
  <entry>
    <title type="html">IstanbulJS Code Coverage Reports in VSTS</title>
    <link href="http://www.westerndevs.com/development/istanbuljs-in-vsts/" rel="alternate" type="text/html"/>
    <id>http://www.westerndevs.com/development/istanbuljs-in-vsts/</id>
    <published>2017-08-03T16:10:00.000Z</published>
    <updated>2017-08-17T15:01:57.513Z</updated>
	<author>
	
	  
	  <name>David Wesst</name>
	  <email>questions@davidwesst.com</email>
	
	  <uri>http://www.westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Here's another dev thing I use: <a href="https://istanbul.js.org/" target="_blank" rel="external">IstanbulJS</a> in <a href="https://www.visualstudio.com/team-services/continuous-integration/" target="_blank" rel="external">Visual Studio Team Services</a> (VSTS) builds and display the test reports as part of the build reports. When a build completes, I get a report like this one.</p><p><img src="https://davidwesst.blob.core.windows.net/blog/istanbuljs-in-vsts/vsts-code-coverage-report.gif" alt="VSTS Build Report with an IstanbulJS code coverage report" title="VSTS Build Report with an IstanbulJS code coverage report"></p><p>I can browse the report right in the build report, and drill into the results for each file.</p><p>This is how I did it.</p><h2>Step 0: Assumptions</h2><p>I'm not going to go into the details on how to setup IstanbulJS or a test suite, but you'll need a project with tests and uses the IstanbulJS command line tool, <a href="https://github.com/istanbuljs/nyc" target="_blank" rel="external">NYC</a>, to run them. My suggestion is to use <a href="https://mochajs.org/" target="_blank" rel="external">Mocha</a> as <a href="http://www.westerndevs.com/development/mocha-in-vsts/">the test report can be integreated into VSTS as well</a>.</p><p>You'll also need a VSTS account, which is free and worth the effort.</p><h2>Step 1: Script Your Command</h2><p>The goal here is to be able to run a script command that will execute the appropriate code coverage command, complete with parameters, easily. I use <a href="https://docs.npmjs.com/misc/scripts" target="_blank" rel="external">npm scripts</a> for this tutorial, but you can use whatever scripting tool you'd like.</p><p>In my case, I like to run the code coverage report everytime I run my Mocha tests. So, I've updated my <code>npm test</code> command in <em>package.json</em> to use NYC. It looks like:</p><figure class="highlight xquery"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="string">"scripts"</span>: &#123;</div><div class="line">  <span class="string">"test"</span>: <span class="string">"./node_modules/.bin/nyc ./node_modules/.bin/mocha --recursive --reporter=mocha-multi-reporters "</span></div><div class="line">&#125;</div></pre></td></tr></table></figure><p>Note, that I don't use globally installed packages. I only use the local ones installed in my <em>node_modules</em> folder.</p><h2>Step 2: Configuring NYC</h2><p>I've configured it in the <em>package.json</em> file with an <code>&quot;nyc&quot;</code> configuration object. Mine looks like this:</p><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="string">"nyc"</span>: &#123;</div><div class="line">  <span class="string">"check-coverage"</span>: <span class="literal">true</span>,</div><div class="line">  <span class="string">"per-file"</span>: <span class="literal">true</span>,</div><div class="line">  <span class="string">"lines"</span>: <span class="number">99</span>,</div><div class="line">  <span class="string">"statements"</span>: <span class="number">99</span>,</div><div class="line">  <span class="string">"functions"</span>: <span class="number">99</span>,</div><div class="line">  <span class="string">"branches"</span>: <span class="number">99</span>,</div><div class="line">  <span class="string">"include"</span>: [</div><div class="line">    <span class="string">"src/**/*.js"</span></div><div class="line">  ],</div><div class="line">  <span class="string">"reporter"</span>: [</div><div class="line">    <span class="string">"text"</span>,</div><div class="line">    <span class="string">"cobertura"</span>,</div><div class="line">    <span class="string">"html"</span></div><div class="line">  ],</div><div class="line">  <span class="string">"report-dir"</span>: <span class="string">"./.test_output/coverage"</span></div><div class="line">&#125;</div></pre></td></tr></table></figure><p>The part of the configuration we care about for this tutorial are the <code>&quot;reporter&quot;</code> and <code>&quot;report-dir&quot;</code> properties. The rest of the configuration is out of scope for this post, but you can learn more in the <a href="https://github.com/istanbuljs/nyc#configuring-nyc" target="_blank" rel="external">nyc README configuration section</a>.</p><p>For <code>&quot;reporters&quot;</code>, you can see that we are using three different reporters. The <em>text</em> reporter is the one that displays in the terminal, the <em>cobertura</em> reporter generates an XML file with all of the results which we'll need, and the <em>html</em> reporter generates the HTML files you saw me browsing at the beginning of this post.</p><p>At this point, when we run <code>npm test</code> we get run our tests and generate the code coverage assets we want.</p><h2>Step 3: Post-Processing the HTML Report</h2><p>This one isn't obvious, but I'm going to save you the trouble of discovering it for yourself.</p><p>That being said, if you don't mind the plain text reports sans-CSS, you can skip this step altogether.</p><p>Our HTML report is going to get displayed in VSTS. Remember, the HTML report isn't just a single file, it's a bunch of HTML files complete with CSS for styling. VSTS doesn't natively load up the extra CSS files, which means we'll need to embed the CSS right into the files themselves to create a copy of the report that'll look good in VSTS.</p><p>Thanks to <a href="http://anthonychu.ca/post/css-styles-vsts-code-coverage/" target="_blank" rel="external">this post from Anthony Chu</a>, I had a headstart on figuring out how to solve this issue. The plan is to run a post-processing script on the <em>posttest</em> script command in npm. I called my script file <em>process-coverage-report.js</em> and updated the scripts section of my <em>package.json</em> to look like this:</p><figure class="highlight xquery"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="string">"scripts"</span>: &#123;</div><div class="line">  <span class="string">"test"</span>: <span class="string">"./node_modules/.bin/nyc ./node_modules/.bin/mocha --recursive --reporter=mocha-multi-reporters "</span>,</div><div class="line">  <span class="string">"posttest"</span>: <span class="string">"node ./tools/process-coverage-report.js"</span></div><div class="line">&#125;,</div></pre></td></tr></table></figure><p>The <em>posttest</em> script will everytime we run <code>npm test</code>. You can also call it directly by running <code>npm run posttest</code> but be sure to have test results for it to process.</p><p>I'll cut to the case, and just show you my post-processing code.</p><figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">let fs = <span class="built_in">require</span>(<span class="string">"fs"</span>),</div><div class="line">    path = <span class="built_in">require</span>(<span class="string">"path"</span>),</div><div class="line">    inline = <span class="built_in">require</span>(<span class="string">"inline-css"</span>);</div><div class="line"></div><div class="line">const TEST_RESULTS_DIRECTORY = <span class="string">"./.test_output"</span>;</div><div class="line">const CODE_COVERAGE_DIRECTORY = <span class="string">"./.test_output/coverage"</span>;</div><div class="line"></div><div class="line">fs.readdir(CODE_COVERAGE_DIRECTORY, <span class="function"><span class="params">(err, files)</span>=&gt;</span> &#123;</div><div class="line">    <span class="keyword">if</span>(err) &#123; <span class="keyword">throw</span> <span class="keyword">new</span> Error(err); &#125;</div><div class="line"></div><div class="line">    let reports = files.filter(<span class="function"><span class="params">(report)</span>=&gt;</span> &#123;</div><div class="line">        <span class="keyword">return</span> report.endsWith(<span class="string">".html"</span>);</div><div class="line">    &#125;);</div><div class="line"></div><div class="line">    reports.forEach(<span class="function"><span class="params">(report)</span>=&gt;</span> &#123;</div><div class="line">        let filePath = path.join(CODE_COVERAGE_DIRECTORY, report);</div><div class="line">        let options = &#123; </div><div class="line">            url: <span class="string">"file://"</span> + path.resolve(filePath),</div><div class="line">            extraCss: <span class="string">".pad1 &#123; padding: 0; &#125;"</span></div><div class="line">        &#125;;</div><div class="line"></div><div class="line">        fs.readFile(path.resolve(filePath), <span class="function"><span class="params">(err, data)</span>=&gt;</span> &#123;</div><div class="line">            inline(data, options)</div><div class="line">                .<span class="keyword">then</span>(<span class="function"><span class="params">(html)</span>=&gt;</span> &#123;</div><div class="line">                    let outputFile = path.join(TEST_RESULTS_DIRECTORY, report);</div><div class="line">                    fs.writeFile(outputFile, html, <span class="function"><span class="params">(err)</span>=&gt;</span> &#123;</div><div class="line">                        <span class="keyword">if</span>(err) &#123; <span class="keyword">throw</span> err; &#125;</div><div class="line">                    &#125;);</div><div class="line">                &#125;)</div><div class="line">                .<span class="keyword">catch</span>(<span class="function"><span class="params">(err)</span>=&gt;</span> &#123;</div><div class="line">                    <span class="built_in">console</span>.log(err);</div><div class="line">                &#125;);</div><div class="line">        &#125;);</div><div class="line">    &#125;);</div><div class="line">&#125;);</div></pre></td></tr></table></figure><p>My build doesn't use a task runner like Gulp I settled on <a href="https://www.npmjs.com/package/inline-css" target="_blank" rel="external">inline-css</a> because I liked the API and it returned promises. If you're using Gulp or Grunt, there are some good options (<a href="https://www.npmjs.com/package/inline-css" target="_blank" rel="external">as suggested by Anthony</a>) for you to create a task to do this for you.</p><p>Now, when you run <code>npm test</code> you'll end up with an extra copy of the HTML report, where you have nothing but HTML files with CSS embedded in the files themselves.</p><h2>Step 4: Adding this to VSTS</h2><p>All you need to do here, is configure your build to use the new code coverage setup. We do that by adding the <em>Publish Code Coverage Results</em> task as a build step and configuring properly. Here's what my configuration looks like:</p><ul><li>Version:  1.*</li><li>Display Name: Publish Code Coverage Results | NYC</li><li>Code Coverage Tool: Cobertura</li><li>Summary File: $(System.DefaultWorkingDirectory)/.test_output/coverage/cobertura-coverage.xml</li><li>Report Directory: $(System.DefaultWorkingDirectory)/.test_output     |</li></ul><p>Your properties may vary, depending on how to configured NYC.</p><h2>Step 5: Done</h2><p>And now we code coverage reporting showing up in VSTS. Huzzah!</p><p>Happy code covering!</p>]]></content>
    
    <summary type="html">
    
      Here&#39;s another dev thing I use: IstanbulJS in Visual Studio Team Services (VSTS) builds and display the test reports as part of the build reports.
    
    </summary>
    
      <category term="development" scheme="http://www.westerndevs.com/categories/development/"/>
    
    
      <category term="javascript" scheme="http://www.westerndevs.com/tags/javascript/"/>
    
      <category term="visual studio team services" scheme="http://www.westerndevs.com/tags/visual-studio-team-services/"/>
    
      <category term="testing" scheme="http://www.westerndevs.com/tags/testing/"/>
    
      <category term="istanbuljs" scheme="http://www.westerndevs.com/tags/istanbuljs/"/>
    
      <category term="nyc" scheme="http://www.westerndevs.com/tags/nyc/"/>
    
  </entry>
  
  <entry>
    <title type="html">Mocha Test Reports in VSTS</title>
    <link href="http://www.westerndevs.com/development/mocha-in-vsts/" rel="alternate" type="text/html"/>
    <id>http://www.westerndevs.com/development/mocha-in-vsts/</id>
    <published>2017-08-01T15:19:00.000Z</published>
    <updated>2017-08-17T15:01:57.513Z</updated>
	<author>
	
	  
	  <name>David Wesst</name>
	  <email>questions@davidwesst.com</email>
	
	  <uri>http://www.westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Here's another dev thing I use: <a href="https://mochajs.org/" target="_blank" rel="external">MochaJS</a> in <a href="https://www.visualstudio.com/team-services/continuous-integration/" target="_blank" rel="external">Visual Studio Team Services (VSTS) builds</a> and display the test reports as part of the build reports. See? Like this.</p><p><img src="https://davidwesst.blob.core.windows.net/blog/mocha-in-vsts/vsts-test-results-in-action.gif" alt="Mocha Test Report in VSTS" title="Screenshot of a MochaJS test report in VSTS"></p><p>This wasn't me trying to fit a square peg into a round hole. VSTS is exceptionally flexible and it comes bundled with all the pieces you need to do this out of the box. The key is making sure that we setup our test runner to produce the output VSTS needs.</p><h2>Step 0: Assumptions</h2><p>I'm not going to explain how to do this, but I'm going to assume you have a project with tests that use <a href="https://mochajs.org/" target="_blank" rel="external">MochaJS</a>. So, you can run <code>mocha</code> from the terminal and your tests run.</p><p>I'm also not going to explain that to use VSTS, you need a VSTS account. They are <a href="https://www.visualstudio.com/team-services/" target="_blank" rel="external">free to start</a> and you'll need one to make this work. It's worth the effort.</p><h2>Step 1: Script Your Test Command</h2><p>Personally, I use <a href="https://docs.npmjs.com/misc/scripts" target="_blank" rel="external">npm scripts</a> for this. I just figure out what my test command is, and then have the <code>npm test</code> script run that. In my project, I run the locally installed version of MochaJS and use the <code>recursive</code> flag.</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="string">./node_modules/.bin/mocha</span> <span class="params">--recursive</span></div></pre></td></tr></table></figure><p>In my <em>package.json</em> file, I have:</p><figure class="highlight xquery"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="string">"scripts"</span>: &#123;</div><div class="line">    <span class="string">"test"</span>: <span class="string">"./node_modules/.bin/mocha --recursive"</span></div><div class="line">&#125;</div></pre></td></tr></table></figure><p>You can just as easily use a Bash or Powershell script for this too if you're not a fan of npm scripts. But you should be.</p><h2>Step 2: Use the mocha-junit-reporter</h2><p>Woah, wait a minute? This is JavaScript not <em>Java</em>.</p><p>I know, but JUnit reports are a standard report format that is supported by VSTS. The key is making sure that our mocha test reports are being output into a format that VSTS can understand. VSTS does not care about your test report to standard out.</p><p>Mocha doesn't come bundled with a JUnit reporter, so I used <a href="https://github.com/michaelleeallen/mocha-junit-reporter" target="_blank" rel="external">mocha-junit-reporter</a> which outputs a <em>test-results.xml</em> file to the root project directory by default. I don't like the default, so I have it output to a directory of my choosing.</p><p>So, first we run: <code>npm install --save-dev mocha-junit-reporter</code></p><p>Then, we update our <code>npm test</code> command in <em>package.json</em> to</p><figure class="highlight xquery"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="string">"scripts"</span>: &#123;</div><div class="line">    <span class="string">"test"</span>: <span class="string">"./node_modules/.bin/mocha --recursive --reporter mocha-unit-reporter --reporter-options mochaFile=./test-output/test-results.xml"</span></div><div class="line">&#125;</div></pre></td></tr></table></figure><p>Don't forget to add test output directory to your <em>.gitignore</em> file.</p><h3>(OPTIONAL) Step 2a: Using Mutliple Reporters</h3><p>But now I can't see my tests in the terminal output!</p><p>I didn't like that either, so I fixed it by using another Mocha extension called <a href="https://github.com/stanleyhlng/mocha-multi-reporters" target="_blank" rel="external">mocha-multi-reporters</a>. It lets us define mutlple reporters for MochaJS and specify reporter parameters in a <em>config.json</em> file that we save in the project root.</p><p>First, install the tool: <code>npm install --save-dev mocha-multi-reporters</code>.</p><p>Then, we update our <code>npm test</code> command to</p><figure class="highlight xquery"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="string">"scripts"</span>: &#123;</div><div class="line">    <span class="string">"test"</span>: <span class="string">"./node_modules/.bin/mocha --recursive --reporter=mocha-multi-reporters"</span></div><div class="line">&#125;</div></pre></td></tr></table></figure><p>And finally, we add a <em>config.json</em> file to the project root. I'm using the spec and mocha-junit-reporter, which result in this <em>config.json</em>:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    <span class="attr">"reporterEnabled"</span>: <span class="string">"spec,mocha-junit-reporter"</span>,</div><div class="line">    <span class="attr">"mochaJunitReporterReporterOptions"</span>: &#123;</div><div class="line">        <span class="attr">"mochaFile"</span>: <span class="string">"./.test_output/test-results.xml"</span></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>It's not perfect, but it works well enough for my purposes.</p><h4>Gotcha! You should use Mocha-Multi</h4><p>I tried using <a href="https://github.com/glenjamin/mocha-multi" target="_blank" rel="external">mocha-multi</a> and I couldn't get it to work with the parameter for <a href="https://github.com/michaelleeallen/mocha-junit-reporter" target="_blank" rel="external">mocha-junit-reporter</a>.</p><h4>Gotcha! This produces an xunit.xml file in the root directory</h4><p>It's a <a href="https://github.com/stanleyhlng/mocha-multi-reporters/issues/35" title="My bug report for the XUnit issue in mocha-multi-reporters" target="_blank" rel="external">bug with mocha-multi-reporters</a> that I've reported. I'm hoping to get a pull request in for it soon, as it's a pretty easy fix.</p><p>The workaround is to add <em>xunit.xml</em> to your <em>.gitignore</em> file and ignore it yourself.</p><h2>Step 3: Run Test Script in your VSTS Build</h2><p>To run your test script, you need to add a build task  in VSTS. In our case, we're adding the NPM buid task, and configuring it to run our <code>npm test</code> command. The build task properties I use are:</p><ul><li>Version: 1.*</li><li>Display Name: npm test</li><li>Command: custom</li><li>Command and arguments: test</li></ul><p>Here's what it looks like:</p><p><img src="https://davidwesst.blob.core.windows.net/blog/mocha-in-vsts/vsts-npm-test-task.png" alt="Screenshot of npm build step" title="Screenshot of VSTS Build Task that runs the tests"></p><h2>Step 4: Publish the Test Results in VSTS</h2><p>For our last step, we need to publish the test results report to VSTS and tell it how to read it.</p><p>We do this with the Publish Test Results build step in VSTS and configure it with the following properties.</p><ul><li>Version: 2.*</li><li>Display name: Publish Test Results | Mocha</li><li>Test result format: JUnit</li><li>Search folder: $(System.DefaultWorkingDirectory)</li></ul><p>Which looks something like this:</p><p><img src="https://davidwesst.blob.core.windows.net/blog/mocha-in-vsts/vsts-publish-test-results.png" alt="VSTS Publish Test Results Build Step" title="Screenshot of VSTS Build Task that consumes the test report"></p><h2>Step 5: Done</h2><p>And with that, you're good to go to capture and explore your MochaJS test results from within your VSTS build report.</p><p>Happy test reporting!</p>]]></content>
    
    <summary type="html">
    
      Here&#39;s another dev thing I do: Display my MochaJS test report in the Visual Studio Team Services (VSTS) build report.
    
    </summary>
    
      <category term="development" scheme="http://www.westerndevs.com/categories/development/"/>
    
    
      <category term="javascript" scheme="http://www.westerndevs.com/tags/javascript/"/>
    
      <category term="visual studio team services" scheme="http://www.westerndevs.com/tags/visual-studio-team-services/"/>
    
      <category term="mocha" scheme="http://www.westerndevs.com/tags/mocha/"/>
    
      <category term="testing" scheme="http://www.westerndevs.com/tags/testing/"/>
    
  </entry>
  
  <entry>
    <title type="html">A review of Scrum for Kanban Teams</title>
    <link href="http://www.westerndevs.com/Kanban/Scrum_for_Kanban_Teams/" rel="alternate" type="text/html"/>
    <id>http://www.westerndevs.com/Kanban/Scrum_for_Kanban_Teams/</id>
    <published>2017-07-14T16:00:00.000Z</published>
    <updated>2017-08-17T15:01:57.513Z</updated>
	<author>
	
	  
	  <name>Dave White</name>
	  <email>dmhwhite@gmail.com</email>
	
	  <uri>http://www.westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Inspired by <a href="https://www.scrum.org/user/119" target="_blank" rel="external">Steve Porter's</a> efforts to bring process practitioners closer together and educate Scrum practitioners, I'm writing a shadow series of posts that will follow the <a href="https://www.scrum.org/resources/blog/scrum-and-kanban-stronger-together" target="_blank" rel="external">Kanban and Scrum - Stronger Together</a> series and continue <a href="https://agileramblings.com/2013/03/10/the-difference-between-the-kanban-method-and-scrum/" target="_blank" rel="external">my own efforts</a> to clear up misconceptions between practitioners of these methods.</p><p><a href="https://www.scrum.org/resources/blog/scrum-primer-kanban-teams" target="_blank" rel="external">In the most recent post in Steve Porter's series</a>, <a href="https://www.linkedin.com/in/yuvalyeret/" target="_blank" rel="external">Yuval Yuret</a> presents Scrum in a manner that is intended to educate Kanban teams.</p><p><strong>Disclaimer</strong></p><p>First off, I have to say that I'm not 100% certain how I feel about <a href="https://www.scrum.org/resources/blog/scrum-primer-kanban-teams" target="_blank" rel="external">Yuval's blog post</a>. It feels like a forced comparison of apples and oranges. But in critically reading it, it forces me to think about why I feel that way. And as always, these are all just my opinions. No harm in sharing them, right?</p><h2>TL;DR</h2><p>In case you haven't read Yuval's post, basically it presents a map of values and practices in Scrum to Kanban language, and encourages Kanban teams to approach Scrum from a practices point of view. It also encourages everyone to review/adopt the values (in Scrum language) that can help software development teams succeed in building software. <a href="https://www.scrum.org/resources/blog/scrum-primer-kanban-teams" target="_blank" rel="external">You should go read it now.</a> :D</p><h2>Values</h2><p>As <a href="https://agileramblings.com/2013/03/10/the-difference-between-the-kanban-method-and-scrum/" target="_blank" rel="external">I wrote in 2013</a>, Scrum and Kanban both share a use of values to encourage users of the methods to behave a certain way. The explicit inclusion of the Scrum Values is a relatively recent (<a href="http://www.scrumguides.org/revisions.html" target="_blank" rel="external">2016 Scrum Guide</a>) addition, but the <a href="http://agilemanifesto.org/" target="_blank" rel="external">Agile Manifesto</a> is definitely a value system and Scrum fully supports those values.</p><p>The Kanban Method also has principles that have been included since its formation. The presentation of these principles have been refined and one addition was made for clarity. And recently, a significant amount of work has been made to further evolve our understanding of the principles and turn them into a description of more concrete values. <a href="https://www.linkedin.com/in/andycarmichael/" target="_blank" rel="external">Andy Carmchael</a> and <a href="https://www.linkedin.com/in/agilemanagement/" target="_blank" rel="external">David J Anderson</a> have created a <strong>free</strong> <a href="http://leankanban.com/guide/" target="_blank" rel="external">Essential Kanban Condensed</a> eBook that lays out the value system for the Kanban Method on Page 3, and <a href="https://www.linkedin.com/in/asplake/" target="_blank" rel="external">Mike Burrows</a> has written a fantastic book <a href="https://www.amazon.ca/Kanban-Inside-Understand-connect-introduce/dp/0985305193/" target="_blank" rel="external">Kanban from the Inside</a> that discusses the values of Kanban in great detail.</p><p>I think it is great that Yuval is including the values mappings in his primer, but I think that some of the mappings he has created reinforce my apples and oranges feelings. He doesn't compare the current state of the art in Kanban values and maps some kanban practices to Scrum values.</p><p>I would encourage you to quickly read the values section (3 minutes) of the <a href="http://leankanban.com/guide/" target="_blank" rel="external">Essential Kanban Condensed</a> eBook starting on Page 3 and judge for yourself how the values comparison feels to you.</p><p>And, as hard as this is to say because I think the values are important, the Scrum guide seems to specify an intent as opposed to a way to think. Values shouldn't be expressed as goals like they are in the Scrum Guide. And maybe that isn't how Scrum is taught. I haven't been to a modern PSM class.</p><h2>Roles</h2><p>I'm glad that Yuval presents the Scrum roles. The Kanban Method neither advocates nor condemns any of these roles. It really has no opinion. The Kanban community has discovered that there are specialists who are good at fulfilling useful services when optimizing virtual kanban systems and participating in Kanban implementations. A Service Request Manager is focused on the needs and expectations of the customer. This is comparable to a Product Owner. A Service Delivery Manager is focused on kanban system performance. A Kanban Coach is focused on organizational adoption.</p><p>To be clear, the Kanban Method has no opinion about roles. It guides people to respect everything until you've gained the emotional maturity as an organization to change. The Kanban community has discovered, in practice, that there are roles and responsibilities that should be encouraged to appear and supported as organizations progress down the Kanban path.</p><h2>Events</h2><p>This is probably the set of things that, regardless of the name, Scrum and Kanban teams will have the most in common. Kanban teams are fully capable of doing everything that Scrum teams do, described as some sort of feedback meetings that happen on a cadence. People on software development teams, regardless of Scrum or Kanban, will goal set, seek feedback, deliver increments of product, and reflect on how they work. If you are a team that is not performing this practices in some form, you should look at either Scrum or Kanban.</p><p>One of the things that is spiritually very different about the Scrum events (as described in the Scrum Guide) and the Kanban feedback meetings is usually that the Scrum events are focusing on what people do during the meeting. Kanban feedback guidance focuses on the work that needs to be done.</p><p>An example of this is the description of the daily stand-up. In the Scrum guide, this is the following description of the daily scrum:</p><blockquote><p>During the meeting, the Development Team members explain:</p><ul><li>What did I do yesterday that helped the Development Team meet the Sprint Goal?</li><li>What will I do today to help the Development Team meet the Sprint Goal?</li><li>Do I see any impediment that prevents me or the Development Team from meeting the Sprint Goal?</li></ul></blockquote><p>In the Kanban community, we have The Kanban Meeting, a daily 'stand-up' style meeting whose focus is work items. You can find a brief description of this meeting on page 25 of <a href="http://leankanban.com/guide/" target="_blank" rel="external">Essential Kanban Condensed</a>. And Yuval also makes this point in his mapping.</p><blockquote><p>Kanban teams typically focus on the flow of work instead of the people doing the work. They work the board right to left focusing on flow problems.</p></blockquote><p>I will state that being prescriptive of what people should do is not necessarily a bad thing. That is one of the things that Kanban has suffered with in that people want prescriptive guidance and in the past, the Kanban community didn't an authoritative source of concrete practices. That has changed dramatically in the last couple years with many initiatives within the Kanban community providing kanban practitioners with examples of concrete practices that could be used prescriptively. <a href="http://leankanban.com/guide/" target="_blank" rel="external">Essential Kanban Condensed</a> provides specific examples. <a href="https://www.amazon.ca/Kanban-Inside-Understand-connect-introduce/dp/0985305193/" target="_blank" rel="external">Enterprise Services Planning</a> or ESP as it is commonly referred as in the Kanban community, is full of specific activities that large organizations adopting Kanban at scale will benefit from implementing and understanding.</p><h2>Artifacts</h2><p>Generally speaking, Yuval hits this point right on the head. Software development teams, striving to be agile, using Scrum or Kanban, will generally need/produce the same things. They need PBIs/User Stories/Work Items to describe demand. They will produce Features/Functions/Components that are cohesive. They will ship increments of software on a cadence or on demand.</p><p>Yuval suggested that Kanban teams limit the size of a product backlog, which may be true in some cases, but this guidance is not from The Kanban Method. Now a days, Kanban teams may have an Upstream Kanban System that is full of work items that are being refined, analyzed, discarded, or finally passed on to the development team as a User Story/PBI that needs to be delivered. Smaller teams can do this within their own kanban system.</p><p><a href="https://www.slideshare.net/lkce/lkce16-upstream-customer-kanban-by-patrick-steyaert" target="_blank" rel="external">Slide 13 in Patrick Steyaert's LKCE2016 presentation</a> shows a good example of the guidance practicing Kanban teams are sharing in the community.</p><h2>Conclusions</h2><p>I think Yuval's options in his conclusion are all viable experiments to try! Kanban teams should never be afraid to take practices from anywhere that they see them. Arguably, kanban actively promotes the constant experimentation of practices to see if they improve the delivery capability of an organization or team.</p><h2>My Final Thoughts</h2><p>While I may disagree with some of the details as outlined in this post, I agree with the spirit of what Yuval is suggesting in his article. Kanban teams need to be open minded when looking for practices that may enhance the way that they work. They should not be afraid to look at Scrum as a source of those activities. And I sincerely hope that everyone came away more educated about Scrum AND Kanban having read these articles.</p><blockquote><p>By this point in the series, I hope that I've encouraged you to learn more about Kanban. And the best place to learn more is a certified training class from a LeanKanban.com Accredited Kanban Trainer. <a href="http://leankanban.com/kmp-i/" target="_blank" rel="external">You can find more about the recommended first class, Kanban System Design, here.</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      A review of a Scrum Primer for Kanban teams
    
    </summary>
    
      <category term="Kanban" scheme="http://www.westerndevs.com/categories/Kanban/"/>
    
    
      <category term="kanban" scheme="http://www.westerndevs.com/tags/kanban/"/>
    
      <category term="agile" scheme="http://www.westerndevs.com/tags/agile/"/>
    
      <category term="scrum" scheme="http://www.westerndevs.com/tags/scrum/"/>
    
      <category term="myths" scheme="http://www.westerndevs.com/tags/myths/"/>
    
  </entry>
  
  <entry>
    <title type="html">Scrum with Kanban Class of Service</title>
    <link href="http://www.westerndevs.com/Kanban/Kanban_Helps_Scrum_with_Emergent_Work/" rel="alternate" type="text/html"/>
    <id>http://www.westerndevs.com/Kanban/Kanban_Helps_Scrum_with_Emergent_Work/</id>
    <published>2017-07-14T16:00:00.000Z</published>
    <updated>2017-08-17T15:01:57.513Z</updated>
	<author>
	
	  
	  <name>Dave White</name>
	  <email>dmhwhite@gmail.com</email>
	
	  <uri>http://www.westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Inspired by <a href="https://www.scrum.org/user/119" target="_blank" rel="external">Steve Porter's</a> efforts to bring process practitioners closer together and educate Scrum practitioners, I'm writing a shadow series of posts that will follow the <a href="https://www.scrum.org/resources/blog/scrum-and-kanban-stronger-together" target="_blank" rel="external">Kanban and Scrum - Stronger Together</a> series and continue <a href="https://agileramblings.com/2013/03/10/the-difference-between-the-kanban-method-and-scrum/" target="_blank" rel="external">my own efforts</a> to clear up misconceptions between practitioners of these methods.</p><p><a href="http://www.westerndevs.com/Kanban/Scrum_with_WIP_Limits/">In my last post</a>, I discussed how a Scrum team could add the concepts of WIP limits to their process and derive measurable delivery performance benefits. In this post, I'm hoping to show how we can use Kanban's concept of Class of Service to help Scrum teams deal with emergent work.</p><h2>Emergent/Unplanned Work</h2><p>One of the things that is very natural in Kanban but less so in Scrum implementations is the ability to deal with emergent or unplanned work during a Sprint. In this case, I am not talking about the anticipated, natural growth of a User Story or PBI as more information is discovered about it. I am talking about un-anticipated work such as emergency issues, newly discovered high-value opportunities, or newly understood schedule risks.</p><p>I want to be clear that Scrum does not mandate that work cannot be introduced into the Sprint. The Scrum Guide allows for a negotiation to occur that would allow work to be introduce into the Sprint if there is capacity available, either by removing an existing PBI or by understanding that there is more room in the sprint than anticipated. In my experience, this does not come naturally to Scrum teams. Years of defending the Sprint backlog make this thinking hard to change.</p><p>But emergent and unplanned work are a reality for many knowledge work teams, especially in our DevOps world where increments of work are discovered, triaged, implemented, and deployed daily, if not many times per day. And as we will learn, this work can be easily tracked, analyzed, and we may be able to anticipate it.</p><h2>A brief Introduction to Class of Service</h2><p>Before I get too deep, I wanted to present a description of Class of Service.</p><blockquote><h3>Description</h3><p>A Class of Service is simply a policy that a team will explicitly create in order to guide team behaviour in scheduling and delivering an increment of work. They may take the form of rules for prioritization, swarming, or delaying the uptake of work by the team. There are 4 classic policy examples (Standard, Expedite, Due Date, Intangible) but you can create more or less. It is important to remember though that they are simply a policy which can be discussed, altered, or abandoned.</p></blockquote><h2>Our First Class of Service</h2><p>As a Scrum team, it is very easy to add your first class of service policy without any significant change to your Scrum practices. We will focus on a very common class of service policy, the <strong>Expedite</strong> class of service. This policy indicates that we have discovered work where the risk of delaying it is higher than we are comfortable with and we need to start a negotiation with the Product Owner about altering the Sprint Plan. We may also have to swarm on the work as a team because the impact of delay is severe. Instances of this type of emergent work happen often in DevOps scenarios where the development team is also responsible for problems that occur in the system in production.</p><p>Our goal with trying out this minimum viable change to our Scrum process is to make expedite work very visible, make it very explicit, and try to understand how this risk mitigation policy is impacting our Sprints.</p><blockquote><p><strong>Note</strong> - By creating an expedite Class of Service policy, we have actually created 2 Class of Service policies. Standard work (everything that is not expedited) and Expedite. Standard work is just <em>normal</em> so we won't really discuss it further.</p></blockquote><h2>The Expedite Lane</h2><p>Keeping in mind our goal with this experiment, the first thing we want to do is simply make the Expedite policy and work visible, and we can easily do this with a simple change to our board. I will continue using our example board from the <a href="http://www.westerndevs.com/Kanban/Scrum_with_WIP_Limits/">previous blog post</a>.</p><p>There are many ways that we can indicate that a work needs to be expedited. We could annotate a card, change its color, or put it in a special place on our board. To keep this simple and in the spirit of using boards, I'm going to suggest that we create a location on our board to indicate that we have an expedite policy and what work is currently affected by that policy.</p><p><img src="https://dl.dropboxusercontent.com/u/30830337/Basic%20Scrum%20Board%20With%20Expedite%20Lane.png" alt="Scrum team's kanban board with Expedite policy depicted as a lane" title="Basic Scrum board with Expedite Lane"></p><p>What you see in the image is a visualization of our policy that indicates:</p><ul><li>we have an explicit Expedite policy</li><li>our policy is that we only work on one expedite item at a time<ul><li>the swimlane has a WIP limit of 1 PBI</li></ul></li></ul><p>What is not clear on my board, but could be made clear with a Definition of Done (DoD) or similar annotations on the board, is</p><ul><li>expedited work is top priority</li><li>teams may be required to swarm to get that work done, which pauses all normally PBIs</li><li>work in the Expedite lane does not obey column WIP limits</li></ul><p>We do not need to alter our cards in any way. Their presence in the lane indicates that the policy is being applied.</p><p>One additional change I would ask a team to make is that once a card enters the expedite lane and is now managed by the policy, mark the card/PBI with some sort of indicator that it was expedited.</p><p>And that is it! We haven't changed how items get into that lane. We will still perform the negotiation with the Product Owner. We probably haven't changed our behaviour around emergent work, but we have made it clear that it is a reality for us and when something is in that lane, we are probably swarming on it if necessary to get it fixed before everything else.</p><h3>So Why Do this?</h3><p>I would suggest using this technique to a team as a possible solution to a few problems.</p><ol><li>There is not clear or commonly understood policy</li><li>There is a problem understanding/communicating when there is emergency work<ul><li>in the team or external to the team</li></ul></li><li>There is a problem understanding how much emergency work there is</li><li>There is a problem understanding how emergency work impacts our Sprint</li><li>There is a problem with the team not being designed to handle this kind of work</li></ol><p>By understanding the problem that prompted the team to adopt this practice, we will understand if the practice is working and/or adding value and make adjustments as necessary.</p><h2>Early Benefits</h2><p>Now that we have an explicit policy and we are tracking our expedited work, we can reflect on that work.</p><p>We can look at how that work flows in conjunction with our normal PBIs and try to determine how one affects the other. Emergency work tends to be disruptive: we put down everything else, re-plan, negotiate, etc. All of these things add to the amount of time it takes for a team to deliver.</p><p>With that information, we could re-design our work flow to minimize the impact of expedites on the PBIs in the original Sprint Plan. We could have a conversation with a sponsor to offload that type of work onto another team. Many opportunities, to design a system that satisfy all the types of work we need to do, can be explored with the information we know have because we are explicitly tracking emergent work.</p><p>And we may discover that while this work is not planned, it can be anticipated. And in anticipating it, we can more effectively deliver all of our work.</p><h2>What's Next</h2><p>Those are just some of the opportunities that you have! I'm not suggesting you can't find those opportunities elsewhere, but you shouldn't be afraid to approach kanban! It will happily support the way you want to work today and help you continue your growth into the future!</p><p>By this point in the series, I hope that I've encouraged you to learn more about Kanban. And the best place to learn more is a certified training class from a LeanKanban.com Accredited Kanban Trainer. <a href="http://leankanban.com/kmp-i/" target="_blank" rel="external">You can find more about the recommended first class, Kanban System Design, here.</a></p><p>In our next post, we will discuss how a Scrum team could enhance their understanding of how long it takes them to deliver a PBI by calculating a Lead Time!</p>]]></content>
    
    <summary type="html">
    
      Kanban&#39;s concept of Class of Service helps Scrum teams deal with emergent work
    
    </summary>
    
      <category term="Kanban" scheme="http://www.westerndevs.com/categories/Kanban/"/>
    
    
      <category term="kanban" scheme="http://www.westerndevs.com/tags/kanban/"/>
    
      <category term="agile" scheme="http://www.westerndevs.com/tags/agile/"/>
    
      <category term="scrum" scheme="http://www.westerndevs.com/tags/scrum/"/>
    
      <category term="myths" scheme="http://www.westerndevs.com/tags/myths/"/>
    
      <category term="class of service" scheme="http://www.westerndevs.com/tags/class-of-service/"/>
    
  </entry>
  
  <entry>
    <title type="html">Estimations and Mistake Driven Development</title>
    <link href="http://www.westerndevs.com/mistakes/Estimations_And_Mistake_Driven_Development/" rel="alternate" type="text/html"/>
    <id>http://www.westerndevs.com/mistakes/Estimations_And_Mistake_Driven_Development/</id>
    <published>2017-07-12T10:00:00.000Z</published>
    <updated>2017-08-17T15:01:57.513Z</updated>
	<author>
	
	  
	  <name>Justin Self</name>
	  <email>justinself@outlook.com</email>
	
	  <uri>http://www.westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Mistake Driven Development, or MDD (because we need another TLA in our lives), is my thought process on how I grow as a human both personally and professionally.</p><a id="more"></a><p>The basic idea is that I, as I'm sure others do, learn best after making mistakes. I can be told the right way to do something and I can follow the approach, but it never <em>really</em> sinks in until I see what happens when I don't do it. The reason I care about things like dependency management or domain models is because I've felt the pain of not using them. It's the pain that drives me to do better. It's the pain that gives me an opportunity to improve. Were it not for the pain, I'd never want to change. For me, I have to make mistakes before I can grow.</p><p>MDD doesn't stop with my technical skill sets. When I married my wife, we were both pretty young (21). I hadn't had a chance to really get myself together and now I had to be a husband. I made several mistakes (we both did but I'd never tell her that) and I felt pain. Sometimes I felt that pain several times because I can be slow learner. But eventually, I find that I want to stop feeling the pain enough to change my ways and that's always when I grow. We're still young and have a lot of years to continue to grow, but I can at least look back as we clear our first decade and see improvements.</p><h2>News Flash: I suck at estimates</h2><p>I've been guilty of trying to anticipate what my client wants to hear and craft a pleasing response that orbits the truth instead of landing on it. This most always manifests itself in over promising. This is an area of particular interest for me. I've felt the pain of over promising (often in the way of low balling estimates) time and time again. I've walked that emotional path so many times that my feet would take me there without any conscious effort on my part. In other words, I was so good at doing it that I sometimes didn't realize I was doing it until it's too late.</p><p>One mistake started out the same way. A client was pressuring me for an estimate. I gave one and she didn't like it. So we &quot;negotiated&quot; until I walked out of the room with a familiar sense of foreboding. As a human, I suck at estimates in general. Put me under the pressure of some forced negotiation (whether real or by my own imagination) and by the end of it I've probably blacked out halfway through and temporarily made my client happy at the expense of several future sleepless nights.</p><hr><p>Before I go any further, in no way am I attempting to blame a client for my lack of directness. A client's job is to maximize value for her company which includes motivating those who work for/with her to deliver quality content quickly. As an executive for the company, she is expected to drive success hard.</p><hr><p>I developed a theory for why I've done this. I think I subconsciously simulate the client interactions with a legitimate, variable estimation. For example, maybe the simulation starts with an estimation I feel comfortable with. If I think she'll blow up, I'll re-estimate the work with the goal of reducing the length of time required. The problem is that this distorts my vision to the point that I began to overestimate my capacity or ability. I also see this as a self fulfilling prophecy of sorts. If I'm too afraid of what the client will do when I say 6 weeks, I'm going to justify a way to myself to say something less.</p><p>This will lead to a new estimate of 5 weeks. She still won't be happy but I'm sure if we work <em>really</em> hard we can <em>possibly</em> get it done in 4 weeks. So I can just tell her 4-5 weeks. Cut to me delivering the estimate and the only thing the client hears is &quot;4 weeks&quot;. Now she doesn't know that I've already tried to cut through the &quot;what if things go perfect&quot; scenario and thinks she can make me work harder to get it done faster by imposing a deadline. Before I know it, I'm walking out of the meeting and the client has used her knife to carve a giant X on a delivery date three weeks from now... Mother Francis.</p><p>So what happens next? I get myself and the team pumped up all the while hoping my face doesn't betray my confident facade. The familiar anxious feeling sits in the bottom of my stomach as if I had extra servings of stone soup. For the next two weeks, I ignore the signs while confidently thinking that we are going to deliver a miracle (with a few swishes of pepto-bismol added for good measure). The last week rolls around and it looks like we are really going to do it. But then something happens, like it does every time. Something happens in the story that we didn't foresee, production blows up and pulls half of the team away, or the client introduces a &quot;simple&quot; change.</p><p>Two or three days before we reach the giant X on the calendar, I realize it's hopeless. I began to think that if I work the next 72 hours, ignoring distractions like sleep, food, or time with my beautiful wife and kids, we <em>might</em> have a 30% chance of making.</p><p>Reality quickly sets in and I began customizing my most dreaded email template. You know what it is: the &quot;we need to delay our release&quot; one.</p><h2>Enough</h2><p>I eventually got tired of this. I was ready to start making changes that would help prevent or control situations like this in the future. I had felt the pain enough now that I was ready to do something about it. This was a great opportunity to let my mistake drive my own development.</p><p>Note: my point isn't to make perfect estimate, I don't even think that's possible. My point is to work  to create more realistic estimations all the while being honest with myself and my client.</p><p>So here are some things I started doing:</p><h3>Embrace the suck</h3><p>When I was a kiddo, if I ever lied to my mother, I would be punished twice as hard (doing the bad thing I lied about + lying). If I have tough news for a client, I embrace the suck and set the expectations from the beginning. Over time, I learned techniques of delivering bad news in ways that weren't so terrible including presenting options for remediation and giving the client a chance to make a business choice regarding the matter.</p><h3>Stop giving estimates to the client the first time I'm presented with the scope of work</h3><p>This seems like a very obvious thing, but the problem is that I would forget about my previous mistakes and over estimate my own ability. Even if the scope is extremely well defined and I know the code base like I know my refrigerator, taking a moment of pause will allow me to clear my mind and provide time for historical reflection. Afterwards, I'll approach the client with an estimation completed free from pressure.</p><h3>Stop giving perfect world estimates</h3><p>If my physics classes taught me anything, it's that there is a perfect world that exists where there is no air resistance and all cows are spherical. Also, in this perfect world, nothing unplanned ever happens. My team suffers no illness, family emergencies, or destroyed laptops. We make no incorrect assumptions and introduce no bugs and every solution comes to us immediately without needing to ponder it for days. Maybe this world does exist... however, it's just not the world we live in.</p><p>The only constant is change. Life is unpredictable and I need to remember that when I'm thinking about how much time we'll need to complete something. While my client might be sympathetic to one of my teammates needing to take a week and half off because of a death in the family, she doesn't want to hear that as an excuse for why we are late. My estimates need to take into account the unknown. Some people call this padding, I'm calling it being realistic.</p><h3>Take my time</h3><p>Sometimes, I'll think that I know the problem and solution set so well that I don't need to dig deeper. Making estimates within a really short period of time is like trying to quickly eat a loaf of bread with a rock hidden inside. When you find that damn rock, it's going to hurt like hell.</p><h3>Involve other people</h3><p>I need to stop thinking I'm always the right person to make the call on how long something will take. I might be the lead on the team, but I'm not the best. It's not my job to know everything. It's my job to utilize my teammates' strengths to create a cohesive tandem of individuals. We should be estimating as a team, not just me. Again, this seems very obvious, but I'm admitting to making this mistake.</p><h3>Stop thinking everyone has my strengths and weaknesses</h3><p>Maybe I really can do something in 3 days. But does that mean everyone on my team will take the same amount of time? I can crank out some front end code pretty dang quickly. But you need me to write a complex SQL query? Hello Google (ok, really it's StackOverflow). Another person on my team might happen to be the person who has to do some CSS work and she might not be very good at it. 79.1% of all developers are intimidated by CSS... yes, I just made that up.</p><h3>Break it down then break it down more</h3><p>We suck at estimates, but we suck gloriously worse the larger the workload is. Breaking the work down into smaller items, taking the aggregate then applying overall ranges has been much more effective for me.</p><p>This isn't an exhaustive list by which I use to do better; it's just a start.</p><h3>But Agile... Scrum?! What about using velocity? Why estimates?</h3><p>I love Scrum and Kanban (each in different scenarios) but when I'm working on an estimate for a client who wants to know how much something is going to cost <strong><em>before</em></strong> they sign the statement of work, sometimes you've just gotta estimate.</p><p>Maybe some of this resonates with you... maybe not. In the end, this is just me pulling back the curtains and showing how I took some mistakes I made and turned them into growth opportunities.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Mistake Driven Development, or MDD (because we need another TLA in our lives), is my thought process on how I grow as a human both personally and professionally.&lt;/p&gt;
    
    </summary>
    
      <category term="mistakes" scheme="http://www.westerndevs.com/categories/mistakes/"/>
    
    
  </entry>
  
  <entry>
    <title type="html">Scrum with Kanban WIP Limits</title>
    <link href="http://www.westerndevs.com/Kanban/Scrum_with_WIP_Limits/" rel="alternate" type="text/html"/>
    <id>http://www.westerndevs.com/Kanban/Scrum_with_WIP_Limits/</id>
    <published>2017-07-07T00:00:00.000Z</published>
    <updated>2017-08-17T15:01:57.513Z</updated>
	<author>
	
	  
	  <name>Dave White</name>
	  <email>dmhwhite@gmail.com</email>
	
	  <uri>http://www.westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Inspired by <a href="https://www.scrum.org/user/119" target="_blank" rel="external">Steve Porter's</a> efforts to bring process practitioners closer together and educate Scrum practitioners, I'm writing a shadow series of posts that will follow the <a href="https://www.scrum.org/resources/blog/scrum-and-kanban-stronger-together" target="_blank" rel="external">Kanban and Scrum - Stronger Together</a> series and continue <a href="https://agileramblings.com/2013/03/10/the-difference-between-the-kanban-method-and-scrum/" target="_blank" rel="external">my own efforts</a> to clear up misconceptions between practitioners of these methods.</p><p>In my last post, I discussed how a Scrum team could change nothing about their process and organically start describing how they work in Kanban terms. In this post, I'm hoping to show a minimally viable change to their process that could lead to enhanced team delivery performance.</p><h2>Scrum's WIP Limit Policy</h2><p>As we described last post, many Scrum teams limit work in progress (WIP) at the beginning of the Sprint by filling the Sprint Plan with work. The teams are given the ownership of deciding how much work to <em>pull</em> into the sprint. In kanban terms, we would probably call this a <a href="https://en.wikipedia.org/wiki/CONWIP" target="_blank" rel="external">CONWIP (CONstant Work In Progress)</a> WIP control policy. We have constant WIP in the sprint, and we don't control WIP at individual stages of the workflow. One thing that Scrum teams will do that doesn't exactly fit with a CONWIP policy is that CONWIP policies normally just counts cards. In Scrum, cards are assigned a <em>relative size</em> value (Story point) that describes the size of the card. So instead of having a CONWIP limit of 5 cards, Scrum teams will a CONWIP policy of 25 story points. That may be 3 cards, it may be 20 cards, depending on the nature of the work.</p><p>We're not going to change that at all. Limiting work in any manner is a <strong>GREAT</strong> start!</p><p>What we can do though is introduce count-based WIP limits at stages in the virtual kanban system. And that is it! Remember we are doing a minimum viable change to minimize risk, build experience and comfort, and see if this even works.</p><h2>Scrum is naturally enhanced by Kanban</h2><p>Kanban practitioners usually strive to enhance the effect of the WIP limit policies on their system, constantly tuning them to get optimal performance. In order to do this, Kanban tends to promote more fine-grained WIP policies at the workflow stage level. This isn't the only place or way that we can use WIP policies, but it is a really great next step for a Scrum team to take.</p><p>So very simply, the next step for Scrum teams to take is to put a WIP limit policy indicator at the top of a their kanban board!</p><p>Let's walk thorough an example and see how simple that would be!</p><h3>Scrum CONWIP policy controlled board</h3><p><img src="https://dl.dropboxusercontent.com/u/30830337/Basic%20Scrum%20Board%20With%20no%20WIP%20limits.png" alt="Scrum Board with CONWIP policy" title="Basic Scrum board with CONWIP policy"></p><p>We can see here that we are only controlling WIP for the entire system by limiting how much work can be pulled in per sprint. This is a great start to limiting WIP, but we might be able to improve the overall flow of work within the team's workflow. I have seen Scrum teams that start <strong>everything</strong> at the beginning of the sprint instead of starting only as much as they can handle and trying to finish that before starting a new story. Starting everything at once isn't good behaviour or encouraged behaviour in a Scrum team, but it happens without any other policies to guide team members to better behaviour.</p><h3>Scrum Board with Workflow Stage WIP control policies added</h3><p><img src="https://dl.dropboxusercontent.com/u/30830337/Basic%20Scrum%20Board%20With%20Basic%20WIP%20limits.png" alt="Scrum Board with WIP Limits per stage policy" title="Basic Scrum board with WIP limits per phase"></p><p>We can see here that we have simply added some indicators of the WIP limit policy on the Kanban board. I just put a few sample numbers in place, but it is now clear what the policy is for the team with regard to pulling the work <strong>through</strong> the sprint and not just pulling work <em>into</em> the sprint.</p><p>So what these numbers mean is that we believe that there should only be <em>n</em> # of PBIs in a stage at once. Anything more is going to lead to emotional distress due to overburdening and probably slow delivery due to multi-tasking. Using these policies as an example, we believe we should only have 2 PBIs in analysis at a time and if someone is not busy in Dev and Test, they can help out with work on Analysis of a PBI to help flow work through the system.</p><p>It is also very important to understand that in the same way that the sprint capacity is determined during the Sprint Planning meeting and adjusted per sprint, these intra-sprint WIP limit policies should be adjusted when there is new information available about the capabilities of the team.</p><p>We also gain and share information about how we believe the team <em>should</em> behave to help deliver PBIs more effectively. We can discuss work and policies instead of discussing people and why they are working a certain way.</p><p>And that is it! That is as easy as it is to add the idea of intra-workflow WIP limit policies to a Scrum team's kanban board. We didn't have to change anything about the way that we worked. We just enhanced and communicated our team's understanding of how we want to work.</p><h2>Did it Work?!?!</h2><p>Before we call this experiment a success, we need to know, did this even work to improve our delivery capability?</p><p>If you're been practicing Scrum for a bit, you will have some historical information and hopefully trend data about your team's ability to deliver Story Points/PBIs to the customer. It is this information that we use in the Sprint Planning meeting to determine what our CONWIP number should be.</p><p>After you've implemented your intra-workflow WIP limit policies, doing nothing else, you should be able to detect if these policies helped you, or hindered you by measuring your Story Point/PBI delivery rate per sprint. You may also be able to capture some qualitative information in your Sprint Retrospective about the positive or negative impact of these policies on the team members.</p><p>If the experiment produced a measurable improvement in your team's ability to delivery, congratulations!! That is great news and I'd love to hear about it!</p><p>If the experiment produced <em>no</em> measurable improvement in your team's delivery rate, congratulations!! You've discovered that it didn't work! And you have more information and I'd love to hear about it!  But if we had hoped to improve and discovered we didn't, we have a decision to make. Revert the changes as easily as removing the WIP limits from your board and continue life as it was before, or dig into why the policies didn't have the desired effect. Did you constantly exceed the WIP limits? Did you not measure all work? We know from experience that reducing WIP should improve delivery rates.</p><p>But again, if you don't want to figure that out, just remove the WIP limits from your board. Easy!</p><h2>Is there more</h2><p>There is more to the Kanban Method and virtual kanban systems, but we were just planning to demonstrate a minimum viable change that gives Scrum teams a chance to try out a little kanban practice. Once we've mastered the understanding of WIP limits and their implementation, we can pick our next technique to start to learn about like demand shaping, kanban system designs that are fit for purpose, capacity allocations, managing emergent work, or any of the other practices that our community uses as we gain experience with Kanban.</p><h2>What's Next</h2><p>Those are just some of the opportunities that you have! I'm not suggesting you can't find those opportunities elsewhere, but you shouldn't be afraid to approach kanban! It will happily support the way you want to work today and help you continue your growth into the future!</p><p>In our next post, we will discuss how a Scrum team could enhance their practices to handle emergent (or emergency) work!</p>]]></content>
    
    <summary type="html">
    
      A natural, easy first step for enhancing Scrum with a Kanban practice is a WIP limit
    
    </summary>
    
      <category term="Kanban" scheme="http://www.westerndevs.com/categories/Kanban/"/>
    
    
      <category term="kanban" scheme="http://www.westerndevs.com/tags/kanban/"/>
    
      <category term="agile" scheme="http://www.westerndevs.com/tags/agile/"/>
    
      <category term="scrum" scheme="http://www.westerndevs.com/tags/scrum/"/>
    
      <category term="myths" scheme="http://www.westerndevs.com/tags/myths/"/>
    
  </entry>
  
  <entry>
    <title type="html">Home Networking - What and Why</title>
    <link href="http://www.westerndevs.com/Networking/Home-Networking-1/" rel="alternate" type="text/html"/>
    <id>http://www.westerndevs.com/Networking/Home-Networking-1/</id>
    <published>2017-07-03T00:00:00.000Z</published>
    <updated>2017-08-17T15:01:57.513Z</updated>
	<author>
	
	  
	  <name>Donald Belcham</name>
	  <email>donald.belcham@igloocoder.com</email>
	
	  <uri>http://www.westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<img style="float: right;padding-left:10px" src="https://www.igloocoder.com/images/network-cables.jpg"><p>Late last year we moved into a new house. Leaving the other house was tough, and not just because I had built out a <a href="https://www.igloocoder.com/2014/03/25/A-solid-foundation/" target="_blank" rel="external">fairly good networking solution</a> for it. Moving into the new house meant a new internet provider and the standard installation of home networking gear that exists in (hundreds of) thousands of houses throughout North America. Not only did we have crap hardward, the installer obviously had taken the path of least resistence when running the wire from the street and locating it in the house. The best part of the installation was that the wire from the street entered into the mechanical room. The install or previous owners had also run a small mess of Cat5 to get from the mechanical room to a central location where the ISP's router was expected to be located. From that location, they had run more wire to an &quot;office&quot; room in another part of the house.</p><p>This setup wasn't a bad one, but it did have it's limitations. The main router had to sit along a wall in the eating area of the kitchen. That router was also the single wireless access point in the house. ISP provided hardware being what it is (substandard at best), the wifi wasn't stable and, in some locations of the house, there was no identifiable signal. The first 6 months living in the new house have been filled with a host of first world problems. But, being the first world, we had solutions at our disposal.</p><h3>Past experience</h3><p>Our old home had similar issues and I solved many of them, but I also introduced a few different problems along the way. At it's roots that house used a Rosewill gigabit switch and a handful of DD-WRT powered routers. If nothing else, these devices were stable...after I solved the long-running issue of random router reboots that, ultimately, were being caused by a loose power plug.</p><p>Probably the biggest ongoing problem in that house was wifi handoffs. There was one DD-WRT wireless access point on each of the three floors in the house. If I moved from the basement to the main floor, my phone (or other device) would stay connected to the basement access point...even if the signal strength dropped to barely noticeable levels. The result was that you could be standing right next to an access point but you wouldn't be connected to it and you'd likely be suffering from a poor connection to another access point. Definitely not a good thing in a house of highly connected and frequently moving people.</p><p>There were a number of things that I really liked about the physical setup in that house, and I knew that I needed to carry them forward to the new one. One of those was the use of a patch panel where all of the wired connections in the house terminated. Being able to easily interact with the different locations throughout the house was a godsend many times. I added more than just the network cables to the patch panel. Using a Keystone based panel I was able to have all of the Cat5e cables in the panel, the coaxial cables and the phone lines all in that one place. Interestingly, I benefited from the patch panel flexibility more times with the coax and phone lines than I did with the network cables.</p><p>One of the other nice thing was the use of a <a href="https://www.amazon.ca/StarTech-com-RKPW081915-19-Inch-Rackmount-Distribution/dp/B0035PS5AE/ref=sr_1_4?ie=UTF8&amp;qid=1493169057&amp;sr=8-4&amp;keywords=rack+pdu" target="_blank" rel="external">PDU in the rack</a>. Instead of having multiple powered devices all searching for a wall plug and, ultimately, resorting to some kind of consumer power bar, I was able to nicely organize the power distribution.</p><p>The final &quot;must have&quot; that I learned in the old house was the use of a wall mount rack. Originally I had aspirations of using a 48U free standing rack for my networking and entertainment needs. Realistically I didn't need that much space. It wasn't just the vertical space of the free standing rack that was overkill, but also the depth. Most rack mount networking hardware doesn't need more than 20 inches of depth. A good wall mount rack can easily provide the depth required. A rack also saves you from having a bunch of crappy shelves holding one-off hardware and a tangle of cables. For me, a wall-mount rack was a must-have.</p><p>I did a lot of good things in the old house. I did a number of bad things too. My only goal was making home-network-v2 better than its predecessor.</p><h3>Needs</h3><img style="float: right;padding-left:10px" src="https://www.igloocoder.com/images/MaslowsHierarchyOfNeeds.jpg"><p>Obviously there were things I thought we needed in our new house network. They weren't &quot;needs&quot; in the same sense as <a href="https://en.wikipedia.org/wiki/Maslow%27s_hierarchy_of_needs" target="_blank" rel="external">Maslow's Hierarchy</a>, but they sure felt important to me.</p><p>Top of the list, which I was constantly hearing about from the other people in the house, was strong, stable WiFi that covered all the areas we used around the house, the inlaw suite and the pool. The longer I waited to build this network, the more I was being reminded of how important this was to the other people in the house.</p><p>I also wanted to setup a good infrastructure base to build from. Strong hardware, good cable management and room for expansion. The expansion part was key. I have lots of plans.</p><h3>Wants</h3><p>There are a lot of things that I want to do with a home network. A big one is supporting my desire to build a full sensor network to track things like water spills/leaks, windows, doors, and many other things. One of the biggest issues with adding those features to a house is that the sensor devices require power. The easiest solution to that was a PoE capable switch and a full 48 ports.</p><p>I also really wanted to completely eliminate all of the ISP provided hardware. The WiFi on it sucks, it reboots randomly and I have little or no control over the patching of it. The biggest challenge here is that the ISP router also provides our TV service.</p><p>One of the goals with moving to this new house was for me to spend some more time in a workshop making sawdust. I'd love to be 100% disconnected while doing that, but the reality is that I do a lot of research/learning about woodworking online. Some internet connectivity in my shop, which is about 150 feet from the house, was pretty high up on my list.</p><h3>Dreams</h3><p>We all have them: plans for our &quot;ideal&quot; network. The platinum plated solution. I'm definitely not immune to this.</p><p>One of the things I hate the most about the default ISP provided solution is that all of the TV set-top boxes get their signals via WiFi. Obviously, the farther from the base unit, the more walls, bad weather, invisible temporary Faraday Cage's, days that end in 'Y' and other things will cause instability in the TV signals. I really wanted to get rid of this and go to a wired solution so that I would know that the TVs would all work whenever I needed to binge watch <s>Master Chef Junior</s> The Expanse. This is <em>not</em> a normal way to configure this provider's TV sytems.</p><p>Another dream was to setup the telephone wiring in a patch panel like I had done at the old house. This might seem like a simple thing to do, but you haven't seen the wiring in the new house. It's a 40+ year old place that has had low voltage wiring cobbled together through its life. Getting all of the different phone jacks routed back to a central location was going to be no small task.</p><h3>Thinking and Planning and Thinking</h3><p>I spent somewhere between 4 and 6 months formulating ideas, prioritizing them, re-thinking possible solutions and scrapping some of them. It was probably one of the best things that I could have done. Instead of rushing into any solution that looked and felt better than what was available when we moved in, I lived with what we had (much to the chagrin of the other WiFi users in the house). I didn't just go out and buy the hardware I thought I needed. I thought through the problem area, researched options, considered if the problem really would exist, looked for alternatives and then re-thought everything.</p><p>I discovered a lot of problems that I would have overlooked if I'd moved faster. Things like the importance of having system management solutions when you're using enterprise level hardware. I found a lot of hardware solutions that I didn't know existed. One of those was front and back cable management trays. I also scrapped a few ideas, like running a buried strand of fiber from the house to the garage.</p><p>There were a few adjustments and ideas that did surface that I couldn't ignore though.</p><h3>Adjustments</h3><img style="float: right;padding-left:10px" src="https://www.igloocoder.com/images/deskphone.jpg"><p>Our new house has the main living quarters and an attached in-law suite. When people are staying in the suite the only way to communicate with them is to walk to their door and knock or to call their cell phones. Since that space isn't going to be occupied full time, installing a separate land-line isn't a good option. I did, however, run across some information on open source VoIP solutions. All I needed was a PoE powered data line and I could put a phone anywhere in the house, inlaw suite or the garage. While not a &quot;need&quot; or a &quot;want&quot;, this idea is certainly on the &quot;dreams&quot; list and likely will happen at some point in the future.</p><p>Another problem that I struggled to solve was how I could monitor people who came to the door of the inlaw suite. It is situated such that I can't see the door or the driveway from any part of the main house. I looked at some IoT-ish video doorbells, but none of them gave me the warm and fuzzies. One night I went down a rabbit hole around IP based video monitoring systems. Not only could I see who was knocking at the door, but I could also put some eyes on other parts of the yard like the detatched garage and the pool. IP based video was not just going to get added to the list or requirements, but it was going to apparear at the &quot;want&quot; level.</p><p>I read a lot of forums as I did research for this project. One night while looking for something completely unrelated I stumbled across a conversation that had an off-hand comment about the UPS that my ISP provides for some of their hardware. It turns out that the way this UPS is connected to the hardware, it only powered the phone functionality when it was running on the battery. That meant that all internet would be cutoff immediately when the power went out...even if there still was signal in the fibre lines. Prior to this little bit of information I had only intended on using a PDU in the rack. A quick trip to Amazon and I was expecting delivery of a 1U UPS that could provide battery backup to the UPS that provides battery backup to the ISP hardware. Because daddy can't be without his internet when the power bumps.</p><h3>Filled to overflowing</h3><p>Our new house has a very nice wood burning fireplace in it, and I spent the better part of the winter sitting by it reading and researching all things networking. It was fun to spend time looking at concepts and problem areas that I used to work with early in my career. I'm not sure if it is the variety of new (to me) hardware and software, or the prospect of building v2 of something, but either way it is something that I was energized by.</p><p>Some of the other Western Devs have asked that I publish a bunch of content around this project, so this is just the first of many.</p>]]></content>
    
    <summary type="html">
    
      Moving into the new house meant a new internet provider and the standard installation of home networking gear that exists in (hundreds of) thousands of houses throughout North America
    
    </summary>
    
      <category term="Networking" scheme="http://www.westerndevs.com/categories/Networking/"/>
    
    
      <category term="networking" scheme="http://www.westerndevs.com/tags/networking/"/>
    
  </entry>
  
  <entry>
    <title type="html">Nothing in Kanban Prevents Scrum</title>
    <link href="http://www.westerndevs.com/Kanban/Nothing_in_Kanban_Prevents_Scrum/" rel="alternate" type="text/html"/>
    <id>http://www.westerndevs.com/Kanban/Nothing_in_Kanban_Prevents_Scrum/</id>
    <published>2017-07-02T00:00:00.000Z</published>
    <updated>2017-08-17T15:01:57.513Z</updated>
	<author>
	
	  
	  <name>Dave White</name>
	  <email>dmhwhite@gmail.com</email>
	
	  <uri>http://www.westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>Inspired by <a href="https://www.scrum.org/user/119" target="_blank" rel="external">Steve Porter's</a> efforts to bring process practitioners closer together and educate Scrum practitioners, I'm writing a shadow series of posts that will follow the <a href="https://www.scrum.org/resources/blog/scrum-and-kanban-stronger-together" target="_blank" rel="external">Kanban and Scrum - Stronger Together</a> series and continue <a href="https://agileramblings.com/2013/03/10/the-difference-between-the-kanban-method-and-scrum/" target="_blank" rel="external">my own efforts</a> to clear up misconceptions between practitioners of these methods.</p><h1>Kanban Easily Supports All of Scrum</h1><p>One of the things that I see very often is a belief that Scrum and Kanban cannot work together and nothing is farther from the true. If we look at one of the core values of <a href="https://agileramblings.com/2013/04/07/kanban-change-catalyst-with-no-changes-planned/" target="_blank" rel="external">The Kanban Method</a> you'll see that the first principle is:</p><blockquote><p>Start with what you do now</p></blockquote><p>This should instantly put many change-fearing professionals at ease with regard to The Kanban Method, if not the practitioner helping you with it. But in this conversation, this should put Scrum team members at ease. There is nothing in the method that will disrespect your current practices or experiences.</p><p><a href="https://www.linkedin.com/in/yuvalyeret/" target="_blank" rel="external">Yuval Yeret</a> has done a great job of giving us a <a href="https://www.scrum.org/resources/blog/kanban-primer-scrum-teams" target="_blank" rel="external">Primer to Kanban from Scrum Teams</a> but I thought I'd step back from that without introducing too much Kanban and try to diminish this fear that you can't do both by showing that it can be done easily.</p><p>One thing that a Scrum team would naturally want to do is understand the parallels or mappings between the two processes. Familiarity promotes comfort, so let's build a bit of a map for a <em>pure</em> Scrum team to describe their approach in Kanban terms because generally speaking, Scrum teams are already <strong>doing kanban</strong>.</p><h2>Sprint/Iteration</h2><p>One of the core tenants of Scrum is the Sprint. This time box is designed to give teams a few things:</p><ol><li>consistent schedule for important, collaborative activities</li><li>control over work selection for the time period</li><li>meet daily to discuss current state and plan for the day</li><li>reduction in changes induced by external parties</li><li>an end date that the delivery team can use as a goal for delivery</li><li>an end date that a customer can use as an expectation</li></ol><p>Scrum achieves these goals by using particular activities around and in the time box. As an example, let us say that a Scrum team has a 2 week Sprint, so at the start of a 2 week period, they replenish their sprint backlog in the Spring Planning meeting. They will select how much work to accept as the goal (Sprint goal/forecast) for the 2 week period. They will <s>not accept</s> <em>strongly discourage</em> changes to the contents of the sprint backlog for the 2 week period. They will meet daily to discuss the current state of things and adjust any daily plans as appropriate. They will strive to complete the Sprint goal (all of the forecasted work) by the end of the Sprint, and they will plan to demonstrate their accomplishments to external parties in a Sprint Review. They will also plan reflect on their own activities and try to identify opportunities to improve their own capabilities in a Sprint Retrospective.</p><p>So what we've discovered is that:</p><ol><li>They have a meeting at the start of the 2 week period to fill the Sprint backlog<ul><li>the Scrum name: Sprint Planning meeting</li><li>The team chooses how much work goes into that backlog</li><li>The team will generally be allowed to finish that work before starting new work</li></ul></li><li>They will meet daily to create effective daily plans<ul><li>the Scrum name: Daily Scrum</li></ul></li><li>They will have a meeting at the end of the 2 week period to review what they have produces<ul><li>The Scrum name: Sprint Review</li></ul></li><li>They will have a meeting at the end of the 2 week period to review their own process<ul><li>the Scrum name: Sprint Retrospective</li></ul></li></ol><p>How do we model that in kanban?</p><h4>Cadences</h4><p>... are the kanban term used to describe the things that happen on schedule. Kanban easily supports the Sprint Planning activity by creating an analogous cadence for a Replenishment activity, where the team interacts with an upstream partner (read: customer) to determine what to work on until the next time we get to meet with the customer. A Scrum team can easily describe their scheduled meeting as happening on predictable cadences.</p><ol><li>Once every two weeks, we will collaborate to fill our backlog<ul><li>a kanban name: Replenishment meeting</li><li>the team understand how much work will occur in 2 weeks</li></ul></li><li>They will meet daily to discuss current state and plan for the day<ul><li>a kanban name: Kanban meeting</li></ul></li><li>Once every two weeks, we will meet to discuss/demonstrate what we've accomplished<ul><li>a kanban name: Product demo</li></ul></li><li>Once every two weeks, we will discuss our own processes with an eye on improvement<ul><li>a kanban name: Service Delivery Review</li></ul></li></ol><h4>WIP Limits</h4><p>... are the kanban equivalent to picking (pulling) the work that we feel we can accomplish and being allowed to focus on finishing that work before starting or being interrupted by new work</p><p>A Scrum team picks how much work to pull into the Sprint. The kanban name for this is a WIP limit. A Kanban team can pull 10 PBIs into their process every 2 weeks.</p><p>In Kanban, teams are not required to put WIP limits on columns. This is a natural growth path for many teams, but it certainly isn't required. A limit on the # of items accepted into the sprint is an acceptable form of limiting WIP. These limits are guides to optimal workflow behaviour, but they are not laws. Kanban teams, just like Scrum teams, can adapt their plan to accomodate newly discovered information.</p><h4>Visualize</h4><p>... is the kanban approach to using visualizations of intangible work (code, features, etc) to help us understand and manager our own process. We typically classify the things as <em>work items</em> but they often have more descriptive names.</p><p>Most Scrum teams already use boards and they use PBIs to describe intangible things like software and code.</p><h2>Is there more</h2><p>There is more to the Kanban Method, but we were just planning to model what a Scrum team does in kanban terms in a comfort-building exercise. Kanban does not require you to remove estimation (planning poker) as a means of filling your sprint. Kanban does not require you to abandon story points as a means of representing <em>size</em> or <em>effort</em>. You can still use story points as a means of measuring <em>how much</em> you did.</p><p>And that's it! Scrum teams visualize work, limit WIP, and have cadences! Any Scrum team can call themselves a Kanban team. They simply need to make the decision.</p><h2>What's Next</h2><p>Well, if you are a new to Kanban team, there is lots of opportunity to grow. You have the opportunity to:</p><ol><li>refine your understanding of your work</li><li>better know who your customers really are</li><li>understand what you do and how you do it<ul><li>how we measure progress</li><li>how we maximize flow (team level)</li></ul></li><li>who are your partners in your organization helping you deliver to your customers<ul><li>how we maximize flow (organization level)</li></ul></li><li>how we scale our approach across the organizations, not just multiple development teams<ul><li>kanban in the HR dept. Who knew?!?! :D</li></ul></li></ol><p>Those are just some of the opportunities that you have! I'm not suggesting you can't find those opportunities elsewhere, but you shouldn't be afraid to approach kanban! It will happily support the way you want to work today!</p>]]></content>
    
    <summary type="html">
    
      Inspired by a colleague
    
    </summary>
    
      <category term="Kanban" scheme="http://www.westerndevs.com/categories/Kanban/"/>
    
    
      <category term="kanban" scheme="http://www.westerndevs.com/tags/kanban/"/>
    
      <category term="agile" scheme="http://www.westerndevs.com/tags/agile/"/>
    
      <category term="scrum" scheme="http://www.westerndevs.com/tags/scrum/"/>
    
      <category term="myths" scheme="http://www.westerndevs.com/tags/myths/"/>
    
  </entry>
  
  <entry>
    <title type="html">Kanban and Scrum Together - Not so fast</title>
    <link href="http://www.westerndevs.com/Kanban/Kanban_and_Scrum_Together/" rel="alternate" type="text/html"/>
    <id>http://www.westerndevs.com/Kanban/Kanban_and_Scrum_Together/</id>
    <published>2017-06-30T00:00:00.000Z</published>
    <updated>2017-08-17T15:01:57.513Z</updated>
	<author>
	
	  
	  <name>Dave White</name>
	  <email>dmhwhite@gmail.com</email>
	
	  <uri>http://www.westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>A colleague of mine who works at Scrum.org now posted a blog about how Kanban and Scrum are stronger together. <a href="https://www.scrum.org/user/119" target="_blank" rel="external">Steve Porter</a> had this to say in his blog post...</p><p><a href="https://www.scrum.org/resources/blog/scrum-and-kanban-stronger-together" target="_blank" rel="external">Kanban and Scrum - Stronger Together</a></p><p>You might find my first comment there if someone at Scrum.org approves it in the pursuit of open and shared discussions.</p><p><img src="https://dl.dropboxusercontent.com/u/30830337/missing-comments-scrum-org.png" alt="Missing Comments??" title="Missing comments on Scrum.org"></p><p><strong>Update</strong> The comments have finally been approved.</p><p>Since it hasn't been approved at the time of me writing this blog post, here it is again...</p><blockquote><p>Hey Steve,</p><p>I've been sitting with this tab open for a month, trying to decide what to say. I felt like it was time to close the tab by providing my thoughts. To be clear, I'm speaking about The Kanban Method when I use the word kanban and I believe that is what this article is talking about when it says Kanban and Scrum are stronger together.</p><p>Let me start out stating that I believe that teams and organizations need to be better at addressing customer demand. That pressure is what drives organizations and teams to adopt a 'process' that they think will help. We would call those processes Scrum and Kanban and that is probably the first point of failure. It is unfortunate that these processes are seen as incompatible and I applaud your decision to try and change that thinking. It isn't the practices that are incompatible, but the religions that sprout up around the organizations that evangelize the processes.</p><p>Part of me is disappointed with the misconceptions of what kanban is and how it can be applied as demonstrated by the comments. Going through some of the the comments, I see...</p><p><strong>Hiren Pandya</strong> ... the requirements needed to transition to kanban.</p><p>Anyone can begin transitioning to kanban at any time because of the lack of prescription of &quot;the one&quot; kanban approach. Kanban has a natural and specific mindset that accommodates the current state and an evolutionary path to maturity, of which we are all at different points in our journey. Honestly, transitioning to kanban is as simple as changing the label we use describe our mindset and values.</p><p><strong>Bruno Baketari</strong> Create hybrids: Beware! --and-- along with an absence of time-boxes or any other time-bound constraint (the Kanban cadences are not constraints).</p><p>The problem with this statement is that any approach that is open to adding/removing practices as their value to the team changes will create a hybrid solution. Kanban by it's very nature creates hybrid solutions as teams take tactical practices from anywhere they choose to enhance they way they deliver value to their customers. The kanban value system openly embraces the concept of taking practices from anywhere that might improve your team/organizations ability to deliver value to customers. It has to accept all practices with respect.</p><p>Regarding cadences not being constraints, I would posit that a Replenishment meeting with a cadence of 2 weeks is exactly the same kind of time-bound constraint as a Sprint Planning meeting that happens every 2 weeks. Practically, they are equivalent constraints.</p><p><strong>Mark Chapman</strong> I don't quite get what the point is here, they have different uses for different teams.</p><p>This seems to be a reinforcement of the myth that Kanban is for Type A teams and Type B teams shouldn't use it. Which is a myth.</p><p><strong>Final Thoughts...</strong></p><p>After reading your article, and the comments, it makes me wonder why people think that a team couldn't implement a fully &quot;Scrum&quot; set of practices and processes and name it Kanban. It is 100% possible to do that. I don't know that the opposite is true, in that a team would fully implement a kanban system and call it Scrum. Kanban allows for far more variation than the Scrum guide does.</p><p>I guess in the long run, we are trying to foster collaboration and enhance the strength of our professions by bringing these two communities together, which I think is very noble and the right thing to do. What I would like to see though is a properly educated discussion about where and how they (Kanban and Scrum) are different (or not) so that people can make decisions from how to describe what they are doing.</p><p>Thank you and <a href="https://www.actionableagile.com/about-us/" target="_blank" rel="external">Dan</a> for stepping forward and taking on this challenge.</p></blockquote><p>(I added some Markdown to simulate the Disqus formatting)</p><p>Steve kindly responded (without approving the original comment) with some questions..</p><blockquote><p>if you can truly transition to a Kanban system as easily as you described</p></blockquote><p>and</p><blockquote><p>if you're not limiting WIP, you're not implementing a Kanban system</p></blockquote><p>I responded with this <s>still considered spam and unapproved</s> comment. <strong>Update</strong> - The comments have finally been approved.</p><blockquote><p>First of all, I spoke of transitioning to The Kanban Method as being very easy. I didn't discuss the implementation of a virtual kanban system as easy, although in truth, most Scrum teams are already using a virtual kanban system.</p><p><a href="https://www.actionableagile.com/about-us/" target="_blank" rel="external">Dan</a> and I have had great conversations about WIP limits. Last time might have been in Germany over cocktails, but it was a great conversation.</p><p>There are many ways to limit WIP. I, and probably Dan too, would actually probably prefer to call it an optimal WIP policy, but if we are speaking only about limiting WIP, there are different kinds of policies along the maturity curve that we can use to limit WIP, all with different pros and cons that are discovered as we go. We choose which of those policies to start with based on organization emotional resistance and education/experience, all the while understanding that we are using this first policy as a starting point and we expect it to change, sometime frequently, as information about team workflow evolves.Some possible policies include...</p><ul><li>A Sprint backlog is a WIP limiting policy.</li><li>A policy of not starting anything new until your current work is done, is a WIP limit.</li><li>Stating everyone can work on 2 things at a time is a WIP limit policy.</li><li>A visual token indicating there is capacity to pull is the visualization of a WIP limit policy.</li><li>Keeping a flow efficiency number high is a WIP limiting policy.</li><li>Canonically, a number at the top of a column on a kanban board is a visualization of an explicit WIP limit policy.</li></ul><p>The problem with WIP policies (and this certainly applies to many Scrum teams I've seen) is that there is usually no penalty for breaking the policy. It is an indicator of bad behaviour if the team violates a WIP limit, but it isn't a law and we acknowledge that sometimes we have to violate our WIP limits due to unforeseen events.</p><p>So while I speak about limiting WIP, I don't necessarily write a # on the kanban board until the team discovers the problem with the # not being on the board, then we decide what to do about it. If I recall correctly, Dan always puts a # on the board, but makes it high enough that there should be no emotional resistance to it, and then he starts talking about lowering it. I think both approaches have merit.</p><p>About 'no WIP limit == no kanban system', generally speaking, I'd state that you have an immature virtual kanban system if you don't have pull-based work scheduling mechanics in play to manage the flow of work. This is subtly different than saying if your not limiting WIP, you're not implementing kanban.</p></blockquote><p>I'm presenting all of this for a couple reasons.</p><ol><li>I don't like being censored</li><li>It is, imho, really important for the community to get access to all of the information</li></ol><p>If someone is going to present two competitive concepts and state that they shouldn't be competitive, that is great. And I've stated that Kanban and Scrum should <strong>not</strong> be seen as competitive and and incompatible.</p><p>But if you are going to explore the merits of each concept and allow for the continued misunderstanding of a either of those concepts in your dialog, you're biased and doing a disservice to the community.</p><p>Please check back soon for my exploration of each comparison that arises as we follow <a href="https://www.scrum.org/resources/blog/scrum-and-kanban-stronger-together" target="_blank" rel="external">Steve's</a> series of posts.</p>]]></content>
    
    <summary type="html">
    
      A colleague of mine who works at Scrum.org now posted a blog about how Kanban and Scrum are stronger together.
    
    </summary>
    
      <category term="Kanban" scheme="http://www.westerndevs.com/categories/Kanban/"/>
    
    
      <category term="kanban" scheme="http://www.westerndevs.com/tags/kanban/"/>
    
      <category term="agile" scheme="http://www.westerndevs.com/tags/agile/"/>
    
      <category term="scrum" scheme="http://www.westerndevs.com/tags/scrum/"/>
    
      <category term="myths" scheme="http://www.westerndevs.com/tags/myths/"/>
    
  </entry>
  
  <entry>
    <title type="html">Dylan Joins Microsoft</title>
    <link href="http://www.westerndevs.com//Dylan-Joins-Microsoft/" rel="alternate" type="text/html"/>
    <id>http://www.westerndevs.com//Dylan-Joins-Microsoft/</id>
    <published>2017-06-13T00:00:00.000Z</published>
    <updated>2017-08-17T15:01:57.513Z</updated>
	<author>
	
	  
	  <name>Dylan Smith</name>
	  <email>optikal@shaw.ca</email>
	
	  <uri>http://www.westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>I'm excited to announce that <strong>Im joining Microsoft!!!</strong>  Ive had a GREAT 6.5 years with <a href="http://www.imaginet.com" target="_blank" rel="external">Imaginet</a> doing DevOps, ALM, Agile, and architecture consulting.  I got the opportunity to work with many smart people on a TON of interesting projects.  And by the way  they are hiring right now!</p><p>My new role at Microsoft is a DevOps Architect on a brand new team whose goal is to drive VSTS and ultimately Azure adoption, in this case by focusing on helping (large) customers apply effective DevOps practices. The idea is to build relationships with Microsoft's biggest customers, and act in an advisory role to help them be successful in deploying things to azure and/or adopting VSTS. One of our first activities will be providing the <a href="https://www.visualstudio.com/vs/enterprise-devops-offer/" target="_blank" rel="external">Enterprise DevOps Accelerator</a> benefit that was announced at the VS 2017 launch.  This is a free 2-week engagement provided by Microsoft or one of our partners to customers that purchase 50+ VS Enterprise licenses.  The goal is to help a customer migrate an application to Azure using DevOps practices and tools (i.e. VSTS). My team will be responsible for those engagements, determining what we can do to add the most value in 2 weeks, delivering some of them ourselves and working with partners to deliver others, and evolving the offering as we learn.</p><p>What I find most exciting is its a brand new team - with the broad goal of helping drive Azure/VSTS adoption via good DevOps  and me (and my team) will have a large amount of autonomy to decide exactly how we go about achieving that goal.  On that note, my first order of business will be building a team  specifically Im looking for a world-class DevOps expert to work alongside me to build the team, and help determine our direction and strategy.  If you or somebody you know are a world-class DevOps expert, please get in touch with me and lets chat!  For now the best way to reach me is <a href="mailto:dylansmith256@hotmail.com" target="_blank" rel="external">dylansmith256@hotmail.com</a></p><p>PS - It will also be nice to not be a billable consultant anymore, not having to always be selling and convincing customers to give us more business.</p>]]></content>
    
    <summary type="html">
    
      After 6.5 rewarding years with Imaginet, I&#39;m joining Microsoft as a DevOps Architect.
    
    </summary>
    
    
      <category term="azure" scheme="http://www.westerndevs.com/tags/azure/"/>
    
      <category term="vsts" scheme="http://www.westerndevs.com/tags/vsts/"/>
    
      <category term="devops" scheme="http://www.westerndevs.com/tags/devops/"/>
    
      <category term="microsoft" scheme="http://www.westerndevs.com/tags/microsoft/"/>
    
  </entry>
  
  <entry>
    <title type="html">Running Kubernetes on Azure Container Services</title>
    <link href="http://www.westerndevs.com/development/Kubernetes_on_azure/" rel="alternate" type="text/html"/>
    <id>http://www.westerndevs.com/development/Kubernetes_on_azure/</id>
    <published>2017-06-07T23:36:36.000Z</published>
    <updated>2017-08-17T15:01:57.513Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>http://www.westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>This blog post will walk through how to set up a small Kubernetes cluster on Azure Container Services, manage it with Kubernetes and do a rolling deployment. You may think that sounds like kind of a lot. You're not wrong. Let's dig right in.</p><p><em>Note:</em> If you're a visual or auditory learner then check out the channel 9 video version of this blog post.</p><p>We're going to avoid using the point and click portal for this entire workflow, instead we'll lean on the really fantastic Azure command line. This tool can be installed locally or you can use the version built into the portal.</p><p><img src="http://i.imgur.com/JjmmFvg.png" alt="Azure CLI in Portal"></p><p>Using the commandline is great for this sort of thing because there are quite a few moving parts and we can use variables to keep track of them. Let's start with all the variables we'll need, we'll divide them up into two sets.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">RESOURCE_GROUP=kubernetes</div><div class="line">REGION=australiasoutheast</div><div class="line">DNS_PREFIX=prdc2017</div><div class="line">CLUSTER_NAME=prdc2017</div></pre></td></tr></table></figure><p>The first set of variables here are needed to stand up the resource group and Azure Container Service. The resource group is called <code>kubernetes</code> which is great for my experiments but not so good for your production system. You'll likely want a better name, or, if you're still governed by legacy IT practices you'll want a name like <code>IL004AB1</code> which encodes some obscure bits of data. Next up is the region in which everything should be created. I chose Australia South-East because it was the first region to have a bug fix I needed rolled out to it. Normally I'd save myself precious hundreds of miliseconds by using a closer region. Finally the DNS_PREFIX and CLUSTER_NAME are used to name items in the ACS deployment.</p><p>Next variables are related to the Azure container registry frequently called ACR.</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="attr">REGISTRY</span>=prdc2017registry</div><div class="line"></div><div class="line"><span class="attr">DOCKER_REGISTRY_SERVER</span>=<span class="variable">$REGISTY</span>.azurecr.io</div><div class="line"><span class="attr">DOCKER_USER_NAME</span>=<span class="variable">$REGISTRY</span></div><div class="line"><span class="attr">DOCKER_PASSWORD</span>=yAZxyNVN8yIs5uln9yNQ</div><div class="line"><span class="attr">DOCKER_EMAIL</span>=stimms@gmail.com</div></pre></td></tr></table></figure><p>Here we define the name of the registry, the URL, and some login credentials for it.</p><p>With the variables all defined we can move on to actually doing things. First off let's create a resource group to hold the twenty or so items which are generated by the default ACS ARM template.</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">az<span class="built_in"> group </span>create --name <span class="variable">$RESOURCE_GROUP</span> --location <span class="variable">$REGION</span></div></pre></td></tr></table></figure><p>This command takes only a few seconds. Next up we need to create the cluster. To create a Linux based cluster we'd run</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">az acs create <span class="attribute">--orchestrator-type</span>=kubernetes --resource-group <span class="variable">$RESOURCE_GROUP</span> <span class="attribute">--name</span>=<span class="variable">$CLUSTER_NAME</span> <span class="attribute">--dns-prefix</span>=<span class="variable">$DNS_PREFIX</span> --generate-ssh-keys</div></pre></td></tr></table></figure><p>Whereas a Windows cluster would vary only slightly and look like:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">az acs create <span class="attribute">--orchestrator-type</span>=kubernetes --resource-group <span class="variable">$RESOURCE_GROUP</span> <span class="attribute">--name</span>=<span class="variable">$CLUSTER_NAME</span> <span class="attribute">--dns-prefix</span>=<span class="variable">$DNS_PREFIX</span> --generate-ssh-keys --windows --admin-password <span class="variable">$DOCKER_PASSWORD</span></div></pre></td></tr></table></figure><p>For the purposes of this article we'll focus on a Windows cluster. You can mix the two in a cluster but that's a bit of an advanced topic. Running this command takes quite some time, typically on the order of 15-20 minutes. However, the command is doing quite a lot: provisioning servers, IP addresses, storage, installing kubernetes,...</p><p>With the cluster up and running we can move onto building the registry (you could actually do them both at the same time, there is no dependency between them).</p><figure class="highlight dsconfig"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#create a registry</span></div><div class="line"><span class="string">az </span><span class="string">acr </span><span class="string">create </span><span class="built_in">--name</span> $<span class="string">REGISTRY </span><span class="built_in">--resource-group</span> $<span class="string">RESOURCE_GROUP </span><span class="built_in">--location</span> $<span class="string">REGION </span><span class="built_in">--sku</span> <span class="string">Basic</span></div><div class="line"><span class="string">#</span><span class="string">assign </span>a <span class="string">service </span><span class="string">principal</span></div><div class="line"><span class="string">az </span><span class="string">ad </span><span class="string">sp </span><span class="built_in">create-for-rbac</span> <span class="built_in">--scopes</span> /<span class="string">subscriptions/</span><span class="string">5c642474-9eb9-</span><span class="string">43d8-8bfa-</span><span class="string">89df25418f39/</span><span class="string">resourcegroups/</span>$<span class="string">RESOURCE_GROUP/</span><span class="string">providers/</span><span class="string">Microsoft.</span><span class="string">ContainerRegistry/</span><span class="string">registries/</span>$<span class="string">REGISTRY </span><span class="built_in">--role</span> <span class="string">Owner </span><span class="built_in">--password</span> $<span class="string">DOCKER_PASSWORD</span></div><div class="line"><span class="string">az </span><span class="string">acr </span><span class="string">update </span>-n $<span class="string">REGISTRY </span><span class="built_in">--admin-enabled</span> <span class="string">true</span></div></pre></td></tr></table></figure><p>The first line creates the registry and the second sets up some credentials for it. Finally we enable admin logins.</p><p>Of course we'd really like our Kubernetes cluster to be able to pull images from the registry so we need to give Kubernetes an idea of how to do that.</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="attribute">az</span> acr credential show -n <span class="variable">$REGISTRY</span></div></pre></td></tr></table></figure><p>This command will dump out the credentials for the admin user. Notice that there are two passwords, either of them should work.</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kubectl create<span class="built_in"> secret </span>docker-registry <span class="variable">$REGISTRY</span> <span class="attribute">--docker-server</span>=https://$DOCKER_REGISTRY_SERVER <span class="attribute">--docker-username</span>=<span class="variable">$REGISTRY</span> <span class="attribute">--docker-password</span>=<span class="string">"u+=+p==/x+E7/b=PG/D=RIVBMo=hQ/AJ"</span> <span class="attribute">--docker-email</span>=<span class="variable">$DOCKER_EMAIL</span></div></pre></td></tr></table></figure><p>The password is the one taken from the previous step, everything else from our variables at the start. This gives Kubernetes the credentials but we still need to instruct it to make use of them as the default. This can be done by editing one of the configuration ymls in Kubernetes.</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kubectl <span class="builtin-name">get</span> serviceaccounts<span class="built_in"> default </span>-o yaml &gt; ./sa.yaml</div></pre></td></tr></table></figure><p>Regreives the YML for service accounts. In there two changes are required: first removing the resource version by deleting <code>resourceVersion: &quot;243024&quot;</code>. Next the credentials need to be specified by adding</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="string">imagePullSecrets:</span></div><div class="line">- <span class="string">name:</span> prdc2017registry</div></pre></td></tr></table></figure><p>This can now be sent back to Kubernetes</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kubectl replace serviceaccounts<span class="built_in"> default </span>-f ./sa.yaml</div></pre></td></tr></table></figure><p>This interaction can also be done in the Kubernetes UI which can be accessed by running</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="attribute">kubectl proxy</span></div></pre></td></tr></table></figure><p>We've got everything set up on the cluster now and can start using it in earnest.</p><h2>Deploying to the Cluster</h2><p>First step is to build a container to use. I'm pretty big into ASP.NET Core so my first stop was to create a new project in Visual Studio and then drop to the command line for packaging. There is probably some way to push containers from Visual Studio using a right click but I'd rather learn it the command line way.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">dotnet <span class="keyword">restore</span></div><div class="line"><span class="keyword">dotnet</span> publish -c <span class="keyword">Release</span> -o <span class="keyword">out</span></div><div class="line">docker <span class="keyword">build</span> -t dockerproject .</div></pre></td></tr></table></figure><p>If all goes well these commands in conjunciton with a simple Dockerfile should build a functional container. I used this docker file</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">FROM</span> microsoft/dotnet:<span class="number">1.1</span>.<span class="number">2</span>-runtime-nanoserver</div><div class="line"><span class="keyword">WORKDIR</span><span class="bash"> /dockerProject</span></div><div class="line"><span class="bash">COPY out .</span></div><div class="line"><span class="bash">EXPOSE 5000</span></div><div class="line"><span class="bash">ENTRYPOINT [<span class="string">"dotnet"</span>, <span class="string">"dockerProject.dll"</span>]</span></div></pre></td></tr></table></figure><p>This container can now make its way to our registry like so</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">docker login <span class="variable">$DOCKER_REGISTRY_SERVER</span> -u <span class="variable">$REGISTRY</span> -<span class="selector-tag">p</span> <span class="string">"u+=+p==/x+E7/b=PG/D=RIVBMo=hQ/AJ"</span></div><div class="line">docker tag dockerproject prdc2017registry<span class="selector-class">.azurecr</span><span class="selector-class">.io</span>/dockerproject:v1</div><div class="line">docker push prdc2017registry<span class="selector-class">.azurecr</span><span class="selector-class">.io</span>/dockerproject:v1</div></pre></td></tr></table></figure><p>This should upload all the layers to the registry. I don't know about you but I'm getting excited to see this thing in action.</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kubectl run dockerproject --image prdc2017registry<span class="selector-class">.azurecr</span><span class="selector-class">.io</span>/dockerproject:v1</div></pre></td></tr></table></figure><p>A bit anti-climactically this is all that is needed to trigger Kubernetes to run the container. Logging into the UI should show the container deployed to a single pod. If we'd like to scale it all that is needed is to increase the replicas in the UI or run</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kubectl scale <span class="attribute">--replicas</span>=3 rc/dockerproject</div></pre></td></tr></table></figure><p>This will bring up two additional replicas so the total is three. Our final step is to expose the service port externally so that we can hit it from a web browser. Exposing a port of Kubernetes works differently depending on what service is being used to host your cluster. On Azure it makes use of the Azure load balancer.</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kubectl expose deployments dockerproject <span class="attribute">--port</span>=5000 <span class="attribute">--type</span>=LoadBalancer</div></pre></td></tr></table></figure><p>This command does take about two minutes to run and you can check on the progress by running</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kubectl <span class="builtin-name">get</span> svc</div></pre></td></tr></table></figure><p>With that we've created a cluster and deployed a container to it.</p><p>##Bonus: Rolling Deployment</p><p>Not much point to having a cluster if you can't do a zero downtime rolling deployment, right? Let's do it!</p><p>You'll need to push a new version of your container up to the registry. Let's call it v2.</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">docker tag dockerproject prdc2017registry<span class="selector-class">.azurecr</span><span class="selector-class">.io</span>/dockerproject:v2</div><div class="line">docker push prdc2017registry<span class="selector-class">.azurecr</span><span class="selector-class">.io</span>/dockerproject:v2</div></pre></td></tr></table></figure><p>Now we can ask Kubernetes to please deploy it</p><figure class="highlight gams"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kubectl <span class="keyword">set</span> image <span class="comment">deployments</span>/dockerproject prdc2017registry.azurecr.io/<span class="comment">dockerproject:v2</span></div></pre></td></tr></table></figure><p>That's it! Now you can just watch in the UI as new pods are stood up, traffic rerouted and the old pods decomissioned.</p><h2>Conclusion</h2><p>It is a credit to the work of mnay thousands of people that it is so simple to set up an entire cluster and push an image to it forget that we can do zero downtime deployments. A cluster like this is a bit expensive to run so you have to be serious about getting good use out of it. Deploy early and deploy often. I'm stoked about containers and orchestration - I hope you are too!</p><p>Oh, and don't forget to tear down you're cluster when you're done playing.</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">az<span class="built_in"> group </span>delete --name <span class="variable">$RESOURCE_GROUP</span></div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      Docker is cool and all but shipping containers to production has a lot of added challenges. Scaling, deploying, rolling deployments, storage,... the list of challenges goes on and on. An orchestration engine, like Kubernetes, can solve many of the challenges.
    
    </summary>
    
      <category term="development" scheme="http://www.westerndevs.com/categories/development/"/>
    
    
      <category term="c#" scheme="http://www.westerndevs.com/tags/c/"/>
    
      <category term="kuberntes" scheme="http://www.westerndevs.com/tags/kuberntes/"/>
    
  </entry>
  
  <entry>
    <title type="html">The Great RS-232 Adventure</title>
    <link href="http://www.westerndevs.com/development/AndroidSerialPorts/" rel="alternate" type="text/html"/>
    <id>http://www.westerndevs.com/development/AndroidSerialPorts/</id>
    <published>2017-05-11T23:36:36.000Z</published>
    <updated>2017-08-17T15:01:57.513Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>http://www.westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>A few days back my buddy <a href="/bios/justin_self">Justin Self</a> found me a pretty good challenge. Although my memory isn't as good as it once was I have a high degree of confidence that the interaction went something like this.</p><p><strong>Scene:</strong> Simon has just walked out of the ocean after having swum between two adjacent tropical islands. As he strolls up to the beach Justin arrives.</p><p><img src="http://imgur.com/WQlOjce.png" alt="100% truthful representation of what it looked like"><em>Photo of expensive and highly accurate recreation of what happened</em></p><p><strong>Justin:</strong> We need somebody to figure out how to get this android tablet to talk over serial to a computer.</p><p><strong>Simon:</strong> You mean over USB?</p><p><strong>Justin:</strong> No, over RS-232 serial. And you need to be able to do it in Xamarin's MonoDroid or Mono for Android or whatever non-copyright infringing name they have for it now.</p><p><strong>Simon:</strong> Well Justin, I've never used Xamarin before, nor have I written an Android app, nor have I ever done communication over a serial port before. I actually know nothing about hardware either.</p><p><strong>Justin:</strong> You're almost overqualified for this...</p><p><strong>Simon:</strong> I'm as qualified as I am to do anything. I'll get right on it - ship me the tablet.</p><p>And that is a very accurate representation of just what happened. My first step was to get the cables I needed. Back in 1996 I had a serial mouse but that fellow is long since gone and I haven't a single serial cable in my house. So I headed over to a local electronics store and threw myself at the mercy of the clerk and elderly electrical engineering type. He soon had me kitted out with all the hardware I needed</p><ul><li>ATEN USB to Serial converter</li><li>6ft straight through serial cable</li><li>F/F gender changer</li><li>Null modem adapter</li></ul><p>My computer didn't have an RS-232 port and neither did anything else in my house so the USB-to-serial converter was key. It installed using built in Windows drivers which was fortunate because the manual that came with it only had instructions for installing on Windows 2000. For the serial cable I took a straight through because I wasn't sure how the tablet was wired. The gender changer was needed to hook things together and the null modem adapter was to switch around the wiring for computer to computer communication. See back in the day you'd actually use different wires to connect two computers than to connect a computer and a mouse or printer or something. Twisted pair Ethernet use to be like that too before the gigabit standard introduced auto-switching.</p><p>A couple of days later a box arrived for me containing the tablet</p><p><img src="http://i.imgur.com/co21I7x.jpg" alt="Image of IoT-800 from http://www.ruggedpcreview.com/3_panels_arbor_iot800.html"><em>Image from http://www.ruggedpcreview.com/3_panels_arbor_iot800.html</em></p><p>It was an Arbor IoT-800 running Android 4.4. As you can see in that picture there are two 9-pin serial ports on the bottom as well as USB ports and an Ethernet jack. A quick ProTip about those USB port: they aren't the sort you can use to hook the tablet up to your computer but rather for hooking up the tablet to external devices. You might be able to get them working for hooking up to a computer but you'd need a USB-crossover cable, which I didn't have and, honestly, I'd never heard of before this.</p><p>My first step was to write something on the Windows side that could talk over serial. I needed to find the COM port that was related to the serial port I had plugged in. To do this I called into the Windows Management Interface, WMI. You need to run as admin to do this*. I enumerated all the serial ports on my machine and picked the one whose name contained USB. I'm not sure what the other one is, possibly something built into the motherboard that doesn't have an external connector.</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">var</span> searcher = <span class="keyword">new</span> ManagementObjectSearcher(<span class="string">"root\\WMI"</span>, <span class="string">"SELECT * FROM MSSerial_PortName"</span>);</div><div class="line"><span class="keyword">string</span> serialPortName = <span class="string">""</span>;</div><div class="line"><span class="keyword">foreach</span> (<span class="keyword">var</span> searchResult <span class="keyword">in</span> searcher.Get())</div><div class="line">&#123;</div><div class="line">    Console.Write(<span class="string">$"<span class="subst">&#123;searchResult[<span class="string">"InstanceName"</span>]&#125;</span> - <span class="subst">&#123;searchResult[<span class="string">"PortName"</span>]&#125;</span>"</span>);</div><div class="line">    <span class="keyword">if</span> (searchResult[<span class="string">"InstanceName"</span>].ToString().Contains(<span class="string">"USB"</span>))</div><div class="line">    &#123;</div><div class="line">        Console.Write(<span class="string">" &lt;--- using this one"</span>);</div><div class="line">        serialPortName = searchResult[<span class="string">"PortName"</span>].ToString();</div><div class="line">    &#125;</div><div class="line">    Console.WriteLine();</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>You can also look in the device manager to see which COM port the device is on but this way is more portable. On my machine I got this output</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Starting</div><div class="line">ACPI\PNP0501\1_0 - COM1</div><div class="line">USB VID_0557&amp;PID_2008\6&amp;2c24ce2e&amp;0&amp;4_0 - COM4 --- using this one</div></pre></td></tr></table></figure><p>Next I needed to open up the port and write some data. Fortunately there is a built-in serial port library in .NET. Depending on which articles you read online the serial drivers might be terrible. I'm not overly concerned about performance on this line at this juncture so I just went with the built in class located in <code>System.IO.Ports</code>.</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> counter = <span class="number">0</span>;</div><div class="line"><span class="keyword">var</span> serialPort = <span class="keyword">new</span> SerialPort(serialPortName, <span class="number">9600</span>);<span class="comment">//COM4 and baud of 9600bit/s to start, ramp up later</span></div><div class="line">serialPort.Open();</div><div class="line"><span class="keyword">while</span>(<span class="literal">true</span>)</div><div class="line">&#123;</div><div class="line">  Console.WriteLine(counter);</div><div class="line">  <span class="keyword">var</span> sendBytes = System.Text.ASCIIEncoding.ASCII.GetBytes(<span class="string">$"hello from the C# program<span class="subst">&#123;counter++&#125;</span>\n"</span>);</div><div class="line">  serialPort.Write(sendBytes, <span class="number">0</span>, sendBytes.Length);</div><div class="line">  Thread.Sleep(<span class="number">1000</span>);</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>Here we just loop over the serial port and ask it to send data every second. I chose the most brutally simplistic things at first: a low baud rate and ASCII encoding.</p><p>Of course there really isn't a way to tell if this is working without having something on the other end to read it... So onto Android. My first stop was to install an SSH server on the machine. After all, this is UNIX system and I know that</p><p><img src="http://i.imgur.com/urrU3hU.jpg" alt="It's a UNIX system!"></p><p>One of the really cool things about Linux is the <code>/dev</code> directory. This directory contains all the devices on your system. So if you pop in there you might see devices like <code>sda0</code> which is actually a partition on your hard drive or <code>/dev/random</code> which is a fun device that just emits random numbers. Go on, try doing <code>cat /dev/random</code> or <code>cat /dev/urandom</code> depending on what your system has. On this IoT-800 there are a whole cluster of devices starting with <code>tty</code>. These are, comically, teletype devices. See back in the good old UNIX days we had dumb terminals for accessing a single computer and those devices showed up as <code>tty</code> devices. Guess how those terminals were connected. Serial. So after some experimentation I was able to figure out that the middle physical port on the device was mapped to <code>/dev/ttyS3</code>.</p><p>With the cables all hooked up I held my breath and ran <code>cat /dev/ttyS3</code> while the program on windows was running. Boom, there in my terminal was what was coming from Windows.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">u0_a74@rk3188:/ $ cat /dev/ttyS3</div><div class="line">hello from the C# program0</div></pre></td></tr></table></figure><p>Linux is awesome. So now all that is needed it to get this working from Xamarin.</p><p>The System.IO.Ports package is not part of the version of .NET which runs on Android so a different approach was necessary. Again Linux to the rescue: we can simply read from the device. Before we do that, however, we need to set the baud on the connection. Normally you'd do this by using stty(1) but this command isn't available on Android and we likely wouldn't have permission to call it anyway.</p><p>What is needed is a native OS call to set up the serial port. Xamarin.Android allows calling to native C functions so let's do that.</p><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;termios.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/stat.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fcntl.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">SetUpSerialSocket</span><span class="params">()</span></span></div><div class="line"><span class="function"></span>&#123;</div><div class="line">    <span class="built_in">printf</span>(<span class="string">"Opening serial port\n"</span>);</div><div class="line">    <span class="keyword">int</span> fd = open(<span class="string">"/dev/ttyS3"</span>, O_RDWR);</div><div class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">termios</span> <span class="title">cfg</span>;</span></div><div class="line">    <span class="built_in">printf</span>(<span class="string">"Configuring serial port\n"</span>);</div><div class="line">    <span class="keyword">if</span> (tcgetattr(fd, &amp;cfg))</div><div class="line">    &#123;</div><div class="line">        <span class="built_in">printf</span>(<span class="string">"tcgetattr() failed\n"</span>);</div><div class="line">        close(fd);</div><div class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    cfmakeraw(&amp;cfg);</div><div class="line">    <span class="built_in">printf</span>(<span class="string">"Setting speed in structure\n"</span>);</div><div class="line">    cfsetispeed(&amp;cfg, B115200);</div><div class="line">    <span class="built_in">printf</span>(<span class="string">"Saving structure\n"</span>);</div><div class="line">    <span class="keyword">if</span>(!tcsetattr(fd, TCSANOW, &amp;cfg))</div><div class="line">    &#123;</div><div class="line">        <span class="built_in">printf</span>(<span class="string">"Serial port configured, mate\n"</span>);</div><div class="line">        close(fd);</div><div class="line">        <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">else</span>&#123;</div><div class="line">        <span class="built_in">printf</span>(<span class="string">"Uh oh\n"</span>);</div><div class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>** argv)</span></span></div><div class="line"><span class="function"></span>&#123;</div><div class="line">    <span class="built_in">printf</span>(<span class="string">"Setting baud on serial port /dev/ttyS3\n"</span>);</div><div class="line">    <span class="keyword">return</span> SetUpSerialSocket();</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>To actually call this function we'll need to compile it. For that we need the Android NDK. Instead of getting into how to do that I'll just link to Nick Desaulniers's <a href="http://nickdesaulniers.github.io/blog/2016/07/01/android-cli/" target="_blank" rel="external">excellent post</a>. I will say that I did the compilation using the Windows Subsystem for Linux which is boss.</p><p>The end result is a libSetBaud.so file, .so being the extension for shared objects. This file should be included in the Android application in Visual Studio. A couple of things seem to be important here: first the file should be in a hierarchy which indicates what sort of processor it runs on. If you need to support more than one processor then you'll need to compile a couple of different versions of the library. I knew that this particular device had an armeabi-v7a so into that folder went the compiled .so file. Second you'll need to set the type on the file to AndroidNativeLibrary.</p><p>Next came exposing the function the function for use in Xamarin. To do that we use the Platform Invocation Service (PInvoke). PInvoke allows calling into unmanaged code in an easy way. All that is needed is to</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">using</span> System;</div><div class="line"><span class="keyword">using</span> System.Linq;</div><div class="line"><span class="keyword">using</span> System.Runtime.InteropServices;</div><div class="line"></div><div class="line"><span class="keyword">namespace</span> <span class="title">SerialMessaging.Android</span></div><div class="line">&#123;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">class</span> <span class="title">BaudSetter</span></div><div class="line">    &#123;</div><div class="line">        [<span class="meta">DllImport(<span class="meta-string">"libSetBaud"</span>, ExactSpelling = true)</span>]</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">extern</span> <span class="keyword">int</span> <span class="title">SetUpSerialSocket</span>(<span class="params"></span>)</span>;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>I'd never had to do this before and it is actually surprisingly easy. Things obviously get way more complex if the function you're calling out to requires more complex types or pointers or file descriptors. I specifically kept the C code to a minimum because I don't trust in my ability to do things with C. If you're more adventurous then you can hook into the Android libraries and make use of things like their logging pipeline instead of <code>printf</code>.</p><p>With this all in place it was possible to spin up an Android application to see if we can get the message from the Windows side. Building on the idea of just reading from the device I started with</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">var</span> readHandle = File.Open(<span class="string">"/dev/ttyS3"</span>, FileMode.Open, FileAccess.Read, FileShare.ReadWrite);</div><div class="line"><span class="keyword">while</span> (<span class="literal">true</span>)</div><div class="line">&#123;</div><div class="line">    <span class="keyword">var</span> readBuffer = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">2000</span>];</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (readHandle.CanRead)</div><div class="line">        readHandle.Read(readBuffer, <span class="number">0</span>, <span class="number">2000</span>);</div><div class="line">    Android.Util.Log.Debug(<span class="string">"serial"</span>, readBuffer);</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>This was able to retrieve bytes out of the device and print them to the Android debug console. Awesome! The problem was that when they came in they weren't all a contiguous block. If the windows side sent <code>hello from the C# program1\n</code> in a loop then we might get the output</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">hel</div><div class="line">lo from the C# </div><div class="line">program1\nh</div><div class="line">ello from the C# program1</div></pre></td></tr></table></figure><p>Uh oh. Guess we'll have to use a stop byte to indicate the end of messages. <code>0x00</code> won't work because the read buffer contains a bunch of those already. For now we can try using <code>0x01</code>. Looking at an ASCII table sending <code>0x03</code>, End of Text might be more appropriate. We add that to the send side with a WireFormatSerializer</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title">WireFormatSerializer</span></div><div class="line">&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">byte</span>[] <span class="title">Serialize</span>(<span class="params"><span class="keyword">string</span> toSerialize</span>)</span></div><div class="line"><span class="function">    </span>&#123;</div><div class="line">        <span class="keyword">var</span> bytes = System.Text.ASCIIEncoding.ASCII.GetBytes(toSerialize);</div><div class="line">        <span class="keyword">var</span> bytesWithSpaceForTerminatingCharacter = <span class="keyword">new</span> <span class="keyword">byte</span>[bytes.Length + <span class="number">1</span>];</div><div class="line">        Array.Copy(bytes, bytesWithSpaceForTerminatingCharacter, bytes.Length);</div><div class="line">        bytesWithSpaceForTerminatingCharacter[bytesWithSpaceForTerminatingCharacter.Length - <span class="number">1</span>] = <span class="number">0x1</span>;</div><div class="line">        <span class="keyword">return</span> bytesWithSpaceForTerminatingCharacter;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>On the receiving side we hook up a BufferedMessageReader whose responsibility it is to read bytes and assemble messages. I decided to push the boat out a bit here and implement an IObservable<string> which would rebuild the messages and emit them as events.</string></p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">public class BufferedMessageReader : IObservable&lt;string&gt;</div><div class="line">&#123;</div><div class="line">    List&lt;IObserver&lt;<span class="keyword">string</span>&gt;&gt; observers = <span class="keyword">new</span> List&lt;IObserver&lt;<span class="keyword">string</span>&gt;&gt;();</div><div class="line">    List&lt;<span class="keyword">byte</span>&gt; freeBytes = <span class="keyword">new</span> List&lt;<span class="keyword">byte</span>&gt;();</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">AddBytes</span>(<span class="params"><span class="keyword">byte</span>[] bytes</span>)</span></div><div class="line"><span class="function">    </span>&#123;</div><div class="line">        <span class="keyword">foreach</span>(<span class="keyword">var</span> freeByte <span class="keyword">in</span> bytes)</div><div class="line">        &#123;</div><div class="line">            <span class="keyword">if</span>(freeByte == <span class="number">0x01</span>)</div><div class="line">            &#123;</div><div class="line">                EndOfMessageEncountered();</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">else</span></div><div class="line">            &#123;</div><div class="line">                freeBytes.Add(freeByte);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> IDisposable <span class="title">Subscribe</span>(<span class="params">IObserver&lt;<span class="keyword">string</span>&gt; observer</span>)</span></div><div class="line"><span class="function">    </span>&#123;</div><div class="line">        <span class="keyword">if</span>(!observers.Contains(observer))</div><div class="line">            observers.Add(observer);</div><div class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Unsubscriber(observers, observer);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">void</span> <span class="title">EndOfMessageEncountered</span>(<span class="params"></span>)</span></div><div class="line"><span class="function">    </span>&#123;</div><div class="line">        <span class="keyword">var</span> deserializer = <span class="keyword">new</span> WireFormatDeserializer();</div><div class="line">        <span class="keyword">var</span> message = deserializer.Deserialize(freeBytes.ToArray());</div><div class="line"></div><div class="line">        <span class="keyword">foreach</span> (<span class="keyword">var</span> observer <span class="keyword">in</span> observers)</div><div class="line">            observer.OnNext(message);</div><div class="line">        freeBytes.Clear();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">class</span> <span class="title">Unsubscriber</span>: <span class="title">IDisposable</span></div><div class="line">    &#123;</div><div class="line">        <span class="keyword">private</span> List&lt;IObserver&lt;<span class="keyword">string</span>&gt;&gt; _observers;</div><div class="line">        <span class="keyword">private</span> IObserver&lt;<span class="keyword">string</span>&gt; _observer;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Unsubscriber</span>(<span class="params">List&lt;IObserver&lt;<span class="keyword">string</span>&gt;&gt; observers, IObserver&lt;<span class="keyword">string</span>&gt; observer</span>)</span></div><div class="line"><span class="function">        </span>&#123;</div><div class="line">            <span class="keyword">this</span>._observers = observers;</div><div class="line">            <span class="keyword">this</span>._observer = observer;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Dispose</span>(<span class="params"></span>)</span></div><div class="line"><span class="function">        </span>&#123;</div><div class="line">            <span class="keyword">if</span> (_observer != <span class="literal">null</span> &amp;&amp; _observers.Contains(_observer))</div><div class="line">                _observers.Remove(_observer);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>Most of this class is boilerplate code for wiring up observers. The crux is that we read bytes into a buffer until we encounter the stop bit which we discard and deserialize the buffer before clearing it ready for the next message. This seemed to work pretty well. There could be some additional work done around the message formats for the wire for instance adding more complete checksums and a retry policy. I'd like to get some experimental data on how well the current set up works in the real world before going to that length.</p><p>On the Android side I wrapped this observable with a thing to actually read the file so it ended up looking like</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title">SerialReader</span></div><div class="line">&#123;</div><div class="line"></div><div class="line">    <span class="keyword">public</span> <span class="keyword">string</span> _device &#123; <span class="keyword">get</span>; <span class="keyword">set</span>; &#125;</div><div class="line"></div><div class="line">    <span class="comment"><span class="doctag">///</span> <span class="doctag">&lt;summary&gt;</span></span></div><div class="line">    <span class="comment"><span class="doctag">///</span> Starts a serial reader on the given device</span></div><div class="line">    <span class="comment"><span class="doctag">///</span> <span class="doctag">&lt;/summary&gt;</span></span></div><div class="line">    <span class="comment"><span class="doctag">///</span> <span class="doctag">&lt;param name="device"&gt;</span>The device to start a reader on. Defaults to /dev/ttyS3<span class="doctag">&lt;/param&gt;</span></span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">SerialReader</span>(<span class="params"><span class="keyword">string</span> device = <span class="string">"/dev/ttyS3"</span></span>)</span></div><div class="line"><span class="function">    </span>&#123;</div><div class="line">        <span class="keyword">if</span> (!device.StartsWith(<span class="string">"/dev/"</span>))</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> ArgumentException(<span class="string">"Device must be /dev/tty&lt;something&gt;"</span>);</div><div class="line">        _device = device;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> BufferedMessageReader reader = <span class="keyword">new</span> BufferedMessageReader();</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> IObservable&lt;<span class="keyword">string</span>&gt; <span class="title">GetMessageObservable</span>(<span class="params"></span>)</span></div><div class="line"><span class="function">    </span>&#123;</div><div class="line">        <span class="keyword">return</span> reader;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">ProcessBytes</span>(<span class="params"><span class="keyword">byte</span>[] bytes</span>)</span></div><div class="line"><span class="function">    </span>&#123;</div><div class="line">        <span class="keyword">int</span> i = bytes.Length - <span class="number">1</span>;</div><div class="line">        <span class="keyword">while</span> (i &gt;= <span class="number">0</span> &amp;&amp; bytes[i] == <span class="number">0</span>)</div><div class="line">            --i;</div><div class="line">        <span class="keyword">if</span> (i &lt;= <span class="number">0</span>)</div><div class="line">            <span class="keyword">return</span>;</div><div class="line">        <span class="keyword">var</span> trimmedBytes = <span class="keyword">new</span> <span class="keyword">byte</span>[i + <span class="number">1</span>];</div><div class="line">        Array.Copy(bytes, trimmedBytes, i + <span class="number">1</span>);</div><div class="line">        reader.AddBytes(trimmedBytes);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Start</span>(<span class="params"></span>)</span></div><div class="line"><span class="function">    </span>&#123;</div><div class="line">        <span class="keyword">var</span> readThread = <span class="keyword">new</span> Thread(<span class="keyword">new</span> ThreadStart(StartThread));</div><div class="line">        readThread.Start();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">StartThread</span>(<span class="params"></span>)</span></div><div class="line"><span class="function">    </span>&#123;</div><div class="line">        <span class="keyword">var</span> readHandle = File.Open(_device, FileMode.Open, FileAccess.Read, FileShare.ReadWrite);</div><div class="line">        <span class="keyword">while</span> (<span class="literal">true</span>)</div><div class="line">        &#123;</div><div class="line">            <span class="keyword">var</span> readBuffer = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">2000</span>];</div><div class="line"></div><div class="line">            <span class="keyword">if</span> (readHandle.CanRead)</div><div class="line">                readHandle.Read(readBuffer, <span class="number">0</span>, <span class="number">2000</span>);</div><div class="line">            ProcessBytes(readBuffer);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>Now listening for messages is as easy as doing</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">BaudSetter.SetupUpSerialSocket(); <span class="comment">//sets up the baud rate</span></div><div class="line"><span class="keyword">var</span> reader = <span class="keyword">new</span> SerialReader(); <span class="comment">//create a new serial reader</span></div><div class="line">reader.GetMessageObservable().Subscribe((message) =&gt; Log(message));<span class="comment">//subscribe to new messages</span></div><div class="line">reader.Start();<span class="comment">//start the listener</span></div></pre></td></tr></table></figure><p>One way communication squared away. Now to get messages back from the tablet to the computer. First stop was writing to the file on Android. Again we can make use of the fact that the serial port is just a file</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title">SerialWriter</span></div><div class="line">&#123;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">string</span> _device &#123; <span class="keyword">get</span>; <span class="keyword">set</span>; &#125;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">SerialWriter</span>(<span class="params"><span class="keyword">string</span> device = <span class="string">"/dev/ttyS3"</span></span>)</span></div><div class="line"><span class="function">    </span>&#123;</div><div class="line">        <span class="keyword">if</span> (!device.StartsWith(<span class="string">"/dev/"</span>))</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> ArgumentException(<span class="string">"Device must be /dev/tty&lt;something&gt;"</span>);</div><div class="line">        _device = device;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Write</span>(<span class="params"><span class="keyword">string</span> toWrite</span>)</span></div><div class="line"><span class="function">    </span>&#123;</div><div class="line">        <span class="keyword">var</span> writeHandle = File.Open(_device, FileMode.Open, FileAccess.ReadWrite, FileShare.ReadWrite);</div><div class="line"></div><div class="line">        <span class="keyword">var</span> bytes = <span class="keyword">new</span> WireFormatSerializer().Serialize(toWrite);</div><div class="line">        <span class="keyword">if</span> (writeHandle.CanWrite)</div><div class="line">        &#123;</div><div class="line">            writeHandle.Write(bytes, <span class="number">0</span>, bytes.Length);</div><div class="line">        &#125;</div><div class="line">        writeHandle.Close();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>Really no more than just writing to a file like normal. Closing the file descriptor after each write seemed to make things work better. On the Windows side the serial port already has a data received event built into it so we can just go and add an event handler.</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">serialPort.DataReceived += DataReceivedHandler;</div></pre></td></tr></table></figure><p>This can then be hooked up like so</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">static</span> BufferedMessageReader reader = <span class="keyword">new</span> BufferedMessageReader();</div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">DataReceivedHandler</span>(<span class="params"></span></span></div><div class="line"><span class="function"><span class="params">                <span class="keyword">object</span> sender,</span></span></div><div class="line"><span class="function"><span class="params">                SerialDataReceivedEventArgs e</span>)</span></div><div class="line"><span class="function"></span>&#123;</div><div class="line">    SerialPort sp = (SerialPort)sender;</div><div class="line"></div><div class="line">    <span class="keyword">var</span> bytesToRead = sp.BytesToRead;<span class="comment">//need to create a variable for this because it can change between lines</span></div><div class="line">    <span class="keyword">var</span> bytes = <span class="keyword">new</span> <span class="keyword">byte</span>[bytesToRead];</div><div class="line">    sp.Read(bytes, <span class="number">0</span>, bytesToRead);</div><div class="line"></div><div class="line">    reader.AddBytes(bytes);</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>And that is pretty much that. This code all put together allows sending and receiving messages on a serial port. You can check out the full example at https://github.com/ClearMeasure/AndroidSerialPort where we'll probably add any improvements we find necessary as we make use of the code.</p><p>*There is probably some way to grant your user account the ability to do this but I didn't look into it</p>]]></content>
    
    <summary type="html">
    
      Talking over the RS-232 serial protocol is a bit of a blast from the past but I needed to use in on an Android tablet from within Xamarin. This is the, painfully complete, story of my journey.
    
    </summary>
    
      <category term="development" scheme="http://www.westerndevs.com/categories/development/"/>
    
    
      <category term="c#" scheme="http://www.westerndevs.com/tags/c/"/>
    
      <category term="xamarin" scheme="http://www.westerndevs.com/tags/xamarin/"/>
    
  </entry>
  
  <entry>
    <title type="html">Transparency</title>
    <link href="http://www.westerndevs.com/podcasts/Transparency/" rel="alternate" type="text/html"/>
    <id>http://www.westerndevs.com/podcasts/Transparency/</id>
    <published>2017-05-09T23:25:00.000Z</published>
    <updated>2017-08-17T15:01:57.513Z</updated>
	<author>
		  
	  <name>Western Devs</name>
	  <email>info@westerndevs.com</email>	  
	
	  <uri>http://www.westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<h3>Synopsis</h3><ul><li>University of Waterloo salary adjustment</li><li>Transparency as a means to resolve the gender gap</li><li>Problems that go away when salaries are publicized</li><li>How do you account for high performers who demand more?</li><li>Pros and cons of salary bands</li><li>The White House diversity pledge</li><li>Preparing for transparency</li><li>Why are North Americans so squeamish about discussing salary?</li><li>Advantages for companies not having to compete on salary</li><li>The effect of an information-based economy vs. a widget-based economy</li><li>&quot;All else being equal&quot;</li></ul>]]></content>
    
    <summary type="html">
    
      Wherein the Western Devs determine if, when, and how companies should publish salary and diversity numbers
    
    </summary>
    
      <category term="podcasts" scheme="http://www.westerndevs.com/categories/podcasts/"/>
    
    
  </entry>
  
  <entry>
    <title type="html">JSON.net not just for serialization</title>
    <link href="http://www.westerndevs.com/json/Json.net-not-just-for-sereialization/" rel="alternate" type="text/html"/>
    <id>http://www.westerndevs.com/json/Json.net-not-just-for-sereialization/</id>
    <published>2017-05-03T15:36:36.000Z</published>
    <updated>2017-08-17T15:01:57.513Z</updated>
	<author>
	
	  
	  <name>Simon Timms</name>
	  <email>stimms@gmail.com</email>
	
	  <uri>http://www.westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>If you happen to head over to <a href="https://www.nuget.org/packages" target="_blank" rel="external">https://www.nuget.org/packages</a> and look at which package has been downloaded the most there is a clear winner: JSON.net. It is in everything, every where. JSON is so wildly ubiquitous that I play a little game with myself when I start a new project: how long can I go before I need to serialize or deserialize JSON and need to pull in JSON.net. I rarely last more than a couple of hours.</p><p>But it turns out that there is a lot more that JSON.net can do.</p><a id="more"></a><p>My good buddy <a href="https://ericflemingblog.wordpress.com/" target="_blank" rel="external">Eric Fleming</a> found this one and I'm really just stealing it from him(although <a href="http://jameschambers.com/" target="_blank" rel="external">James</a> claims he found it). The problem that we were trying to solve was that we wanted to patch together a new JSON object out of a bunch of C# objects. It could have been done by building a new DTO, mapping a number of objects to it and then serializing it to JSON. This was kind of a lot of work. Static languages are nice but chucking together ad hoc objects isn't a strong suit. In this case we used JObject to structure the new object</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> <span class="title">Program</span></div><div class="line">&#123;</div><div class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">Main</span>(<span class="params"><span class="keyword">string</span>[] args</span>)</span></div><div class="line"><span class="function">    </span>&#123;</div><div class="line">        <span class="keyword">var</span> sock = <span class="keyword">new</span> Sock&#123;</div><div class="line">            Colour = <span class="string">"blue"</span>,</div><div class="line">            Size = <span class="string">"medium"</span></div><div class="line">        &#125;;</div><div class="line">        <span class="keyword">var</span> shoe = <span class="keyword">new</span> Shoe&#123;</div><div class="line">            Material = <span class="string">"leather"</span></div><div class="line">        &#125;;</div><div class="line">        <span class="keyword">var</span> ensemble = JObject.FromObject(sock);</div><div class="line">        ensemble.Merge(JObject.FromObject(shoe));</div><div class="line">        Console.WriteLine(ensemble.ToString());</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">class</span> <span class="title">Sock</span>&#123;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">string</span> Colour &#123;<span class="keyword">get</span>; <span class="keyword">set</span>;&#125;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">string</span> Size &#123;<span class="keyword">get</span>; <span class="keyword">set</span>;&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">class</span> <span class="title">Shoe</span>&#123;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">string</span> Material&#123;<span class="keyword">get</span>; <span class="keyword">set</span>;&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>The output looks like</p><figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">  <span class="attr">"Colour"</span>: <span class="string">"blue"</span>,</div><div class="line">  <span class="attr">"Size"</span>: <span class="string">"medium"</span>,</div><div class="line">  <span class="attr">"Material"</span>: <span class="string">"leather"</span></div><div class="line">&#125;</div></pre></td></tr></table></figure><p>This approach can be useful in a number of scenarios</p><ul><li>Treating an object as a mixin and applying it to a bunch of differently shaped JSON</li><li>Merging existing JSON with C# objects</li></ul><p>The latter scenario can be achieved like so</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">var</span> hatJObject = JObject.Parse(<span class="string">@"</span></div><div class="line"><span class="string">                &#123;</span></div><div class="line"><span class="string">                    'HatSize': 'Large'</span></div><div class="line"><span class="string">                &#125;</span></div><div class="line"><span class="string">            "</span>);</div><div class="line"><span class="keyword">var</span> ensemble = JObject.FromObject(sock);</div><div class="line"><span class="keyword">var</span> shoeJObject = JObject.FromObject(shoe);</div><div class="line">shoeJObject.Merge(JObject.FromObject(shoeLace));</div><div class="line">ensemble.Merge(shoeJObject);</div><div class="line">ensemble.Merge(hatJObject);</div></pre></td></tr></table></figure><p>This outputs</p><figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">  <span class="attr">"Colour"</span>: <span class="string">"blue"</span>,</div><div class="line">  <span class="attr">"Size"</span>: <span class="string">"medium"</span>,</div><div class="line">  <span class="attr">"Material"</span>: <span class="string">"leather"</span>,</div><div class="line">  <span class="attr">"LaceLength"</span>: <span class="number">30</span>,</div><div class="line">  <span class="attr">"HatSize"</span>: <span class="string">"Large"</span></div><div class="line">&#125;</div></pre></td></tr></table></figure><p>There are also <code>JObject.Load</code> and <code>JObject.Read</code> for reading from JSON streams.</p><p>Newtonsoft.JSON is such a well known and well developed library that it is a shame to just use <code>JsonConvert</code> methods when there is such additional richness.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;If you happen to head over to &lt;a href=&quot;https://www.nuget.org/packages&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://www.nuget.org/packages&lt;/a&gt; and look at which package has been downloaded the most there is a clear winner: JSON.net. It is in everything, every where. JSON is so wildly ubiquitous that I play a little game with myself when I start a new project: how long can I go before I need to serialize or deserialize JSON and need to pull in JSON.net. I rarely last more than a couple of hours.&lt;/p&gt;
&lt;p&gt;But it turns out that there is a lot more that JSON.net can do.&lt;/p&gt;
    
    </summary>
    
      <category term="json" scheme="http://www.westerndevs.com/categories/json/"/>
    
    
      <category term="json.net" scheme="http://www.westerndevs.com/tags/json-net/"/>
    
      <category term="c#" scheme="http://www.westerndevs.com/tags/c/"/>
    
  </entry>
  
  <entry>
    <title type="html">Conquest April 2017 Devblog</title>
    <link href="http://www.westerndevs.com/devblog/Conquest-April-2017-Devblog/" rel="alternate" type="text/html"/>
    <id>http://www.westerndevs.com/devblog/Conquest-April-2017-Devblog/</id>
    <published>2017-05-02T12:31:41.000Z</published>
    <updated>2017-05-02T12:31:41.000Z</updated>
	<author>
	
	  
	  <name>David Wesst</name>
	  <email>questions@davidwesst.com</email>
	
	  <uri>http://www.westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<p>This is the April 2017 update for my video game project I call &quot;Conquest&quot;.</p><a id="more"></a><p>This month, I have continued to make progress on my game project. The unexpected thing that happened was the fact that I decided to take a step back and do some research and development before continuing forward with the game idea I have in mind.</p><h2>Status Update</h2><p>Here's the thing: my game project is too big. At least for now, it's too big, and I don't have enough experience and knowledge to be cofortable taking this idea and turning it into a game.</p><p>It's my first original video game, after all, and if you watch or read game design resources like <a href="https://www.youtube.com/user/ExtraCreditz" target="_blank" rel="external">Extra Credits</a>, you'll often hear that you should start small and move up from there.</p><p>So that's what I did. And I made <a href="https://github.com/davidwesst/breakout" target="_blank" rel="external">Breakout</a> by following <a href="https://developer.mozilla.org/en-US/docs/Games/Tutorials/2D_Breakout_game_pure_JavaScript" target="_blank" rel="external">this MDN</a> tutorial.</p><p><img src="http://i.imgur.com/TnoJp0Gm.png" alt=""></p><p>I know that this isn't going to blow anyone's mind, but it's first game I've made with nothing but vanilla JavaScript and let me get familiar with the basics of JavaScript game development, without blindly relaying on a framework.</p><p>I intend on continuing with this breakout game for another month as I prepare for <a href="http://prairiedevcon.com/" target="_blank" rel="external">Prairie Dev Con</a> to add some polish, clean up the code, and maybe add a few gameplay elements that I worked on this month.</p><p>But now, onto the update.</p><h3>What I've Done</h3><p>Like last time, I'll keep it short and in bullet points:</p><ul><li>Development<ul><li>Did an automated deployment to <a href="https://itch.io/" target="_blank" rel="external">Itch.io</a> using Powershell and VSTS</li><li>Experimented with the <a href="http://www.inklestudios.com/ink/" target="_blank" rel="external">Ink</a> dialogue system and found how to integrate into build</li><li>Taken a step back on Conquest, in lieu of more R&amp;D through smaller games</li><li>Created <a href="https://github.com/davidwesst/breakout" target="_blank" rel="external">Breakout</a> with vanilla ES6 JavaScript, complete with a transpiler and SystemJS modules<ul><li>Thanks <a href="https://github.com/chrinkus/" target="_blank" rel="external">Chris</a> for the suggestion and <a href="https://love2dev.com/" target="_blank" rel="external">Chris Love from Love2Dev</a> for providing constructive feedback regarding framework dependent developers.</li></ul></li><li>Setup my Vim development environment to be extra cool.</li></ul></li><li>Design<ul><li>Met with an <em>actual video game writer</em> to talk about the best way to start including narrative and dialogue into a game<ul><li>Thanks <a href="http://www.rmorganslade.ca/" target="_blank" rel="external">R. Morgan Slade</a> for taking the time and providing some really good feedback and insight</li></ul></li><li>Started migrating some design elements from Conquest into Breakout</li></ul></li></ul><h3>What I've Faced</h3><p>This month, the big thing I faced was the realization that my project is too big for me. It's not that I don't think I would finish it eventually. It's that I don't think I have the skills to make the game fun when I'm done with it.</p><p>I also realized that I am too dependent on frameworks when it comes to game development. It's not that I don't think frameworks have a place or that I'll eventually use one or more of them in my game. It's that I don't know what the framework brings to the table other than an abstraction in development.</p><p>There are plenty of game design tools with full UI's that remove the need to code everything from the ground up, but since I've opted to go the code-focused route because that's what I know best, I should probably know a bit more about the layers code before I start abstracting them away.</p><h3>Where I'm Going</h3><p>May is going to be busy with Prarie Dev Con happening in June, but that won't stop me from working on Conquest. I should also document these discoveries I make a little more, so I'll be doing that through the blog.</p><p>That being said, my plan is to focus on polishing up Breakout by using some of the planned features for Conquest in Breakout. They might not work all that well in that game, but the goal of Breakout isn't to make it a hit, but to experiment with these systems I have planned for Conquest.</p><p>To summarize, here's the plan:</p><ul><li>Refactor Breakout to have a cleaner code base (i.e. modules, objects, etc...)</li><li>Share my VSTS game development discoveries via my blog</li><li>Add some polish to Breakout to complete it</li><li>Prepare my demos for <a href="http://prairiedevcon.com/" target="_blank" rel="external">Prairie Dev Con</a> using Breakout as the demo project</li></ul><h2>Conclusion</h2><p>What I've concluded this month is that I need to make games that match my skills as software developer. For that reason, I'm going to focus on learning the guts of the JavaScript by improving my vanilla JS Breakout game.</p><p>All in all, this month has been quite the shift in direction. I went from making one big game, to making one small game that has nothing to do with the original. It's been challenging, but in a good way. Now I can move forward with developing these systems in smaller pieces, refine them, and eventually recombine them into my original game design.</p><p>See you next month.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This is the April 2017 update for my video game project I call &amp;quot;Conquest&amp;quot;.&lt;/p&gt;
    
    </summary>
    
      <category term="devblog" scheme="http://www.westerndevs.com/categories/devblog/"/>
    
    
      <category term="javascript" scheme="http://www.westerndevs.com/tags/javascript/"/>
    
      <category term="vsts" scheme="http://www.westerndevs.com/tags/vsts/"/>
    
      <category term="conquest" scheme="http://www.westerndevs.com/tags/conquest/"/>
    
      <category term="ink" scheme="http://www.westerndevs.com/tags/ink/"/>
    
      <category term="itch.io" scheme="http://www.westerndevs.com/tags/itch-io/"/>
    
  </entry>
  
  <entry>
    <title type="html">Working From Home</title>
    <link href="http://www.westerndevs.com/podcasts/working-from-home/" rel="alternate" type="text/html"/>
    <id>http://www.westerndevs.com/podcasts/working-from-home/</id>
    <published>2017-04-23T20:43:26.000Z</published>
    <updated>2017-08-17T15:01:57.513Z</updated>
	<author>
		  
	  <name>Western Devs</name>
	  <email>info@westerndevs.com</email>	  
	
	  <uri>http://www.westerndevs.com</uri>
	</author>
    
    <content type="html"><![CDATA[<h3>Synopsis</h3><ul><li>Round table: Who works from home?</li><li>What hours do you keep?</li><li>Handling meetings</li><li>Separating work time from home time</li><li>The importance of a routine</li><li>Interruptions</li><li>Ensuring you put in the hours</li><li>Do you account for water cooler time?</li><li>Remote friendly vs. remote first organizations</li><li>Training your family</li><li>Are you lonely?</li><li>Getting out of the house</li><li>Competing globally</li><li>Communication</li><li>Do you have to work from <em>home</em>?</li><li>Vacation</li><li>Co-working spaces</li><li>Staying focused</li><li>Do you even eat (healthy), bro?</li></ul>]]></content>
    
    <summary type="html">
    
      Yeah, so Pokemon Go was still a thing when we originally recorded this. Add procrastination to the list of hazards for working from home.
    
    </summary>
    
      <category term="podcasts" scheme="http://www.westerndevs.com/categories/podcasts/"/>
    
    
  </entry>
  
</feed>
